#!/usr/bin/env python3
"""
ë„¤ì´ë²„ ë¶€ë™ì‚° í¬ë¡¤ë§ ë°ì´í„°ë¥¼ Supabase ë°ì´í„°ë² ì´ìŠ¤ë¡œ ë³€í™˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import json
import re
import os
from datetime import datetime
from decimal import Decimal
from typing import Dict, List, Optional, Tuple
from supabase import create_client, Client
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SupabaseDataProcessor:
    """í¬ë¡¤ë§ ë°ì´í„°ë¥¼ Supabase DBë¡œ ì²˜ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, supabase_url: str, supabase_key: str):
        """
        Args:
            supabase_url: Supabase í”„ë¡œì íŠ¸ URL
            supabase_key: Supabase API í‚¤
        """
        self.supabase: Client = create_client(supabase_url, supabase_key)
        
    def parse_price_to_amount(self, price_text: str) -> Optional[int]:
        """ê°€ê²© í…ìŠ¤íŠ¸ë¥¼ ë§Œì› ë‹¨ìœ„ ìˆ«ìë¡œ ë³€í™˜"""
        if not price_text or price_text == "ì •ë³´ì—†ìŒ":
            return None
            
        try:
            # "14ì–µ 5,000" -> 145000 (ë§Œì›)
            # "8ì–µ" -> 80000 (ë§Œì›) 
            # "3ì²œë§Œì›" -> 3000 (ë§Œì›)
            
            # ì–µ ë‹¨ìœ„ ì²˜ë¦¬
            billion_match = re.search(r'(\d+)ì–µ\s*(\d+)?', price_text)
            if billion_match:
                billion = int(billion_match.group(1)) * 10000  # ì–µ -> ë§Œì›
                thousand = int(billion_match.group(2) or 0) * 1000 if billion_match.group(2) else 0
                return billion + thousand
                
            # ì²œë§Œì› ë‹¨ìœ„ ì²˜ë¦¬
            thousand_match = re.search(r'(\d+)ì²œë§Œì›?', price_text)
            if thousand_match:
                return int(thousand_match.group(1)) * 1000
                
            # ë§Œì› ë‹¨ìœ„ ì²˜ë¦¬
            man_match = re.search(r'(\d+)ë§Œì›?', price_text)
            if man_match:
                return int(man_match.group(1))
                
            # ìˆ«ìë§Œ ìˆëŠ” ê²½ìš° (ë§Œì› ë‹¨ìœ„ë¡œ ê°€ì •)
            number_match = re.search(r'(\d+)', price_text)
            if number_match:
                return int(number_match.group(1))
                
        except Exception as e:
            logger.warning(f"ê°€ê²© íŒŒì‹± ì˜¤ë¥˜: {price_text} -> {e}")
            
        return None
        
    def parse_area_to_sqm(self, area_text: str) -> Optional[float]:
        """ë©´ì  í…ìŠ¤íŠ¸ë¥¼ ã¡ ë‹¨ìœ„ë¡œ ë³€í™˜"""
        if not area_text:
            return None
            
        try:
            # "121.35ã¡" -> 121.35
            sqm_match = re.search(r'(\d+\.?\d*)ã¡', area_text)
            if sqm_match:
                return float(sqm_match.group(1))
                
            # "37í‰" -> 122.31 (í‰ -> ã¡ ë³€í™˜: 1í‰ = 3.3058ã¡)
            pyeong_match = re.search(r'(\d+\.?\d*)í‰', area_text)
            if pyeong_match:
                return float(pyeong_match.group(1)) * 3.3058
                
        except Exception as e:
            logger.warning(f"ë©´ì  íŒŒì‹± ì˜¤ë¥˜: {area_text} -> {e}")
            
        return None
        
    def extract_floor_number(self, floor_text: str) -> Optional[int]:
        """ì¸µìˆ˜ í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ì ì¶”ì¶œ"""
        if not floor_text:
            return None
            
        try:
            floor_match = re.search(r'(\d+)ì¸µ', floor_text)
            if floor_match:
                return int(floor_match.group(1))
        except Exception as e:
            logger.warning(f"ì¸µìˆ˜ íŒŒì‹± ì˜¤ë¥˜: {floor_text} -> {e}")
            
        return None
        
    def process_complex_basic_info(self, data: Dict) -> Dict:
        """ë‹¨ì§€ ê¸°ë³¸ ì •ë³´ ì²˜ë¦¬"""
        basic_info = data.get('complex_basic_info', {})
        
        return {
            'complex_id': basic_info.get('complex_id', 'unknown'),
            'complex_name': basic_info.get('complexName', 'ì •ë³´ì—†ìŒ'),
            'address': basic_info.get('address', 'ì •ë³´ì—†ìŒ'),
            'completion_year': self.parse_completion_year(basic_info.get('completionYear')),
            'total_households': self.parse_int_safe(basic_info.get('totalHouseholds')),
            'source_url': basic_info.get('source_url', ''),
            'screenshot_path': data.get('detailed_analysis', {}).get('screenshot_path', '')
        }
        
    def parse_completion_year(self, year_text: str) -> Optional[int]:
        """ì¤€ê³µë…„ë„ íŒŒì‹±"""
        if not year_text or year_text == "ì •ë³´ì—†ìŒ":
            return None
            
        try:
            # "2030ë…„", "2030" ë“±ì—ì„œ ë…„ë„ ì¶”ì¶œ
            year_match = re.search(r'(19|20)\d{2}', str(year_text))
            if year_match:
                year = int(year_match.group(0))
                # í•©ë¦¬ì ì¸ ë²”ìœ„ ì²´í¬
                if 1900 <= year <= 2050:
                    return year
        except Exception as e:
            logger.warning(f"ì¤€ê³µë…„ë„ íŒŒì‹± ì˜¤ë¥˜: {year_text} -> {e}")
            
        return None
        
    def parse_int_safe(self, value) -> Optional[int]:
        """ì•ˆì „í•œ ì •ìˆ˜ ë³€í™˜"""
        if not value:
            return None
            
        try:
            if isinstance(value, (int, float)):
                return int(value)
            elif isinstance(value, str):
                # ë¬¸ìì—´ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œ
                number_match = re.search(r'\d+', value)
                if number_match:
                    return int(number_match.group(0))
        except Exception as e:
            logger.warning(f"ì •ìˆ˜ ë³€í™˜ ì˜¤ë¥˜: {value} -> {e}")
            
        return None
        
    def process_current_listings(self, data: Dict, complex_id: str) -> List[Dict]:
        """í˜„ì¬ ë§¤ë¬¼ ì •ë³´ ì²˜ë¦¬"""
        listings = data.get('current_listings', [])
        processed_listings = []
        
        for listing in listings:
            try:
                processed_listing = {
                    'complex_id': complex_id,
                    'listing_index': listing.get('index', 0),
                    'deal_type': listing.get('deal_type', 'ì •ë³´ì—†ìŒ'),
                    'price_display': listing.get('price', ''),
                    'price_amount': self.parse_price_to_amount(listing.get('price', '')),
                    'monthly_rent': self.parse_price_to_amount(listing.get('monthly_rent', '')),
                    'area_sqm': self.parse_area_to_sqm(listing.get('area', '')),
                    'floor_info': listing.get('floor', ''),
                    'description': listing.get('text', '')[:500],  # ê¸¸ì´ ì œí•œ
                    'raw_text': listing.get('raw_text', '')[:1000]  # ê¸¸ì´ ì œí•œ
                }
                processed_listings.append(processed_listing)
                
            except Exception as e:
                logger.error(f"ë§¤ë¬¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                continue
                
        return processed_listings
        
    def process_transaction_history(self, data: Dict, complex_id: str) -> List[Dict]:
        """ì‹¤ê±°ë˜ê°€ ì •ë³´ ì²˜ë¦¬"""
        transactions = data.get('transaction_history', [])
        processed_transactions = []
        
        for transaction in transactions:
            try:
                processed_transaction = {
                    'complex_id': complex_id,
                    'pattern_type': transaction.get('pattern_type', 0),
                    'match_text': transaction.get('match_text', '')[:200],
                    'context_text': transaction.get('context', '')[:500],
                    'price_amount': self.extract_price_from_transaction(transaction.get('match_text', '')),
                    'area_sqm': self.extract_area_from_transaction(transaction.get('match_text', '')),
                    'transaction_type': self.extract_deal_type_from_transaction(transaction.get('match_text', ''))
                }
                processed_transactions.append(processed_transaction)
                
            except Exception as e:
                logger.error(f"ê±°ë˜ë‚´ì—­ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                continue
                
        return processed_transactions
        
    def extract_price_from_transaction(self, text: str) -> Optional[int]:
        """ê±°ë˜ë‚´ì—­ í…ìŠ¤íŠ¸ì—ì„œ ê°€ê²© ì¶”ì¶œ"""
        return self.parse_price_to_amount(text)
        
    def extract_area_from_transaction(self, text: str) -> Optional[float]:
        """ê±°ë˜ë‚´ì—­ í…ìŠ¤íŠ¸ì—ì„œ ë©´ì  ì¶”ì¶œ"""
        return self.parse_area_to_sqm(text)
        
    def extract_deal_type_from_transaction(self, text: str) -> str:
        """ê±°ë˜ë‚´ì—­ í…ìŠ¤íŠ¸ì—ì„œ ê±°ë˜ìœ í˜• ì¶”ì¶œ"""
        if 'ë§¤ë§¤' in text:
            return 'ë§¤ë§¤'
        elif 'ì „ì„¸' in text:
            return 'ì „ì„¸'
        elif 'ì›”ì„¸' in text:
            return 'ì›”ì„¸'
        return 'ê¸°íƒ€'
        
    def process_detailed_prices(self, data: Dict, complex_id: str) -> List[Dict]:
        """ìƒì„¸ ê°€ê²© ì •ë³´ ì²˜ë¦¬"""
        detailed_analysis = data.get('detailed_analysis', {})
        all_prices = detailed_analysis.get('all_prices', [])
        processed_prices = []
        
        for price_text in all_prices:
            try:
                processed_price = {
                    'complex_id': complex_id,
                    'price_text': price_text,
                    'price_amount': self.parse_price_to_amount(price_text),
                    'price_type': self.extract_deal_type_from_transaction(price_text),
                    'source_section': 'ìƒì„¸ë¶„ì„'
                }
                processed_prices.append(processed_price)
                
            except Exception as e:
                logger.error(f"ìƒì„¸ê°€ê²© ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                continue
                
        return processed_prices
        
    def process_complex_areas(self, data: Dict, complex_id: str) -> List[Dict]:
        """ë‹¨ì§€ ë©´ì  ì •ë³´ ì²˜ë¦¬"""
        basic_info = data.get('complex_basic_info', {})
        areas = basic_info.get('areas', [])
        processed_areas = []
        
        seen_areas = set()  # ì¤‘ë³µ ì œê±°ìš©
        
        for area_text in areas:
            try:
                area_sqm = self.parse_area_to_sqm(area_text)
                if area_sqm and area_sqm not in seen_areas:
                    processed_area = {
                        'complex_id': complex_id,
                        'area_sqm': area_sqm,
                        'area_pyeong': round(area_sqm / 3.3058, 2)  # ã¡ -> í‰ ë³€í™˜
                    }
                    processed_areas.append(processed_area)
                    seen_areas.add(area_sqm)
                    
            except Exception as e:
                logger.error(f"ë©´ì  ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                continue
                
        return processed_areas
        
    def process_price_analysis(self, data: Dict, complex_id: str) -> Dict:
        """ê°€ê²© ë¶„ì„ ë°ì´í„° ì²˜ë¦¬"""
        price_analysis = data.get('price_analysis', {})
        
        return {
            'complex_id': complex_id,
            'analysis_date': datetime.now().date(),
            'total_listings': len(data.get('current_listings', [])),
            'total_transactions': len(data.get('transaction_history', [])),
            'price_min': price_analysis.get('price_range', {}).get('min', 0),
            'price_max': price_analysis.get('price_range', {}).get('max', 0),
            'price_avg': int(price_analysis.get('avg_price', 0)),
            'deal_type_summary': price_analysis.get('deal_type_count', {}),
            'areas_count': len(data.get('complex_basic_info', {}).get('areas', [])),
            'floors_count': len(data.get('detailed_analysis', {}).get('floors', []))
        }
        
    def process_crawl_metadata(self, data: Dict, complex_id: str) -> Dict:
        """í¬ë¡¤ë§ ë©”íƒ€ë°ì´í„° ì²˜ë¦¬"""
        metadata = data.get('crawl_metadata', {})
        
        return {
            'complex_id': complex_id,
            'crawl_method': metadata.get('method', 'unknown'),
            'crawl_timestamp': datetime.fromisoformat(metadata.get('crawled_at', datetime.now().isoformat())),
            'total_prices_extracted': metadata.get('total_prices', 0),
            'success': True,
            'error_message': None,
            'raw_data': data  # ì „ì²´ JSON ë°ì´í„° ì €ì¥
        }
        
    async def insert_complex_data(self, json_file_path: str) -> bool:
        """í¬ë¡¤ë§ JSON íŒŒì¼ì„ Supabaseì— ì‚½ì…"""
        try:
            # JSON íŒŒì¼ ì½ê¸°
            with open(json_file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
            complex_id = data.get('complex_basic_info', {}).get('complex_id', 'unknown')
            logger.info(f"ë‹¨ì§€ {complex_id} ë°ì´í„° ì²˜ë¦¬ ì‹œì‘...")
            
            # 1. ê¸°ë³¸ ì •ë³´ ì‚½ì…
            complex_info = self.process_complex_basic_info(data)
            result = self.supabase.table('apartment_complexes').upsert(complex_info).execute()
            logger.info(f"âœ… ë‹¨ì§€ ê¸°ë³¸ì •ë³´ ì‚½ì…: {complex_info['complex_name']}")
            
            # 2. ë©´ì  ì •ë³´ ì‚½ì…
            areas_data = self.process_complex_areas(data, complex_id)
            if areas_data:
                self.supabase.table('complex_areas').upsert(areas_data).execute()
                logger.info(f"âœ… ë©´ì  ì •ë³´ {len(areas_data)}ê°œ ì‚½ì…")
                
            # 3. í˜„ì¬ ë§¤ë¬¼ ì‚½ì…
            listings_data = self.process_current_listings(data, complex_id)
            if listings_data:
                self.supabase.table('current_listings').upsert(listings_data).execute()
                logger.info(f"âœ… ë§¤ë¬¼ ì •ë³´ {len(listings_data)}ê°œ ì‚½ì…")
                
            # 4. ê±°ë˜ë‚´ì—­ ì‚½ì…
            transactions_data = self.process_transaction_history(data, complex_id)
            if transactions_data:
                self.supabase.table('transaction_history').upsert(transactions_data).execute()
                logger.info(f"âœ… ê±°ë˜ë‚´ì—­ {len(transactions_data)}ê°œ ì‚½ì…")
                
            # 5. ìƒì„¸ ê°€ê²© ì‚½ì…
            prices_data = self.process_detailed_prices(data, complex_id)
            if prices_data:
                self.supabase.table('detailed_prices').upsert(prices_data).execute()
                logger.info(f"âœ… ìƒì„¸ê°€ê²© {len(prices_data)}ê°œ ì‚½ì…")
                
            # 6. ê°€ê²© ë¶„ì„ ì‚½ì…
            analysis_data = self.process_price_analysis(data, complex_id)
            self.supabase.table('price_analysis').upsert(analysis_data).execute()
            logger.info(f"âœ… ê°€ê²© ë¶„ì„ ì‚½ì…")
            
            # 7. ë©”íƒ€ë°ì´í„° ì‚½ì…
            metadata = self.process_crawl_metadata(data, complex_id)
            self.supabase.table('crawl_metadata').upsert(metadata).execute()
            logger.info(f"âœ… ë©”íƒ€ë°ì´í„° ì‚½ì…")
            
            logger.info(f"ğŸ‰ ë‹¨ì§€ {complex_id} ë°ì´í„° ì‚½ì… ì™„ë£Œ!")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ì‚½ì… ì˜¤ë¥˜: {e}")
            return False

# ì‚¬ìš© ì˜ˆì‹œ
async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # Supabase ì„¤ì • (í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ì§ì ‘ ì…ë ¥)
    SUPABASE_URL = os.getenv('SUPABASE_URL', 'YOUR_SUPABASE_URL')
    SUPABASE_KEY = os.getenv('SUPABASE_KEY', 'YOUR_SUPABASE_KEY')
    
    if SUPABASE_URL == 'YOUR_SUPABASE_URL':
        print("âš ï¸ Supabase URLê³¼ í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”!")
        print("export SUPABASE_URL='your_url'")
        print("export SUPABASE_KEY='your_key'")
        return
        
    processor = SupabaseDataProcessor(SUPABASE_URL, SUPABASE_KEY)
    
    # í¬ë¡¤ë§ ë°ì´í„° íŒŒì¼ë“¤ ì²˜ë¦¬
    data_dir = "data/output"
    json_files = [f for f in os.listdir(data_dir) if f.endswith('_comprehensive_.json')]
    
    print(f"ğŸ“ {len(json_files)}ê°œ JSON íŒŒì¼ ë°œê²¬")
    
    for json_file in json_files:
        file_path = os.path.join(data_dir, json_file)
        print(f"\nğŸ”„ ì²˜ë¦¬ ì¤‘: {json_file}")
        
        success = await processor.insert_complex_data(file_path)
        if success:
            print(f"âœ… {json_file} ì²˜ë¦¬ ì™„ë£Œ")
        else:
            print(f"âŒ {json_file} ì²˜ë¦¬ ì‹¤íŒ¨")

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
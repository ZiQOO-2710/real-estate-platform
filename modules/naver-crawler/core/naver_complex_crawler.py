"""
ë„¤ì´ë²„ ë¶€ë™ì‚° ë‹¨ì§€ë³„ ëª¨ë“ˆí™” í¬ë¡¤ëŸ¬
Playwright MCPë¥¼ í™œìš©í•œ ë²”ìš© ë‹¨ì§€ í¬ë¡¤ë§ ëª¨ë“ˆ

ì‚¬ìš©ë²•:
    crawler = NaverComplexCrawler()
    result = await crawler.crawl_complex(complex_url)
"""

import asyncio
import json
import csv
from datetime import datetime
from pathlib import Path
from playwright.async_api import async_playwright
import re

class NaverComplexCrawler:
    """ë„¤ì´ë²„ ë¶€ë™ì‚° ë‹¨ì§€ í¬ë¡¤ëŸ¬ ëª¨ë“ˆ"""
    
    def __init__(self, headless=False, screenshot=True):
        """
        Args:
            headless (bool): í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ ì—¬ë¶€
            screenshot (bool): ìŠ¤í¬ë¦°ìƒ· ì €ì¥ ì—¬ë¶€
        """
        self.browser = None
        self.page = None
        self.headless = headless
        self.screenshot = screenshot
        
    async def init_browser(self):
        """ë¸Œë¼ìš°ì € ì´ˆê¸°í™” (F12 ì°¨ë‹¨ ìš°íšŒ)"""
        playwright = await async_playwright().start()
        
        # ì•ˆí‹° ë””í…ì…˜ ë¸Œë¼ìš°ì € ì„¤ì •
        self.browser = await playwright.chromium.launch(
            headless=self.headless,
            args=[
                '--disable-blink-features=AutomationControlled',
                '--disable-features=VizDisplayCompositor',
                '--disable-ipc-flooding-protection',
                '--disable-renderer-backgrounding',
                '--disable-backgrounding-occluded-windows',
                '--disable-client-side-phishing-detection',
                '--disable-component-extensions-with-background-pages',
                '--disable-default-apps',
                '--disable-extensions',
                '--disable-features=TranslateUI',
                '--disable-hang-monitor',
                '--disable-web-security',
                '--no-first-run',
                '--no-default-browser-check',
                '--no-sandbox',
                '--disable-setuid-sandbox'
            ]
        )
        
        context = await self.browser.new_context(
            viewport={'width': 1920, 'height': 1080},
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        )
        
        self.page = await context.new_page()
        
        # ê°œë°œìë„êµ¬ íƒì§€ ìš°íšŒ
        await self.page.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined,
            });
            
            delete window.console.debug;
            delete window.console.clear;
            
            Object.defineProperty(navigator, 'languages', {
                get: () => ['ko-KR', 'ko', 'en-US', 'en'],
            });
            
            Object.defineProperty(navigator, 'plugins', {
                get: () => [1, 2, 3, 4, 5],
            });
        """)
        
    async def extract_complex_basic_info(self, url):
        """ë‹¨ì§€ ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ"""
        print(f"ğŸ” ë‹¨ì§€ ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ: {url}")
        
        try:
            await self.page.goto(url, wait_until="networkidle", timeout=30000)
            await asyncio.sleep(5)
            
            # ë‹¨ì§€ëª… ì¶”ì¶œ (URLì—ì„œë„ ì¶”ì¶œ)
            complex_id = self.extract_complex_id_from_url(url)
            
            basic_info = await self.page.evaluate("""
                () => {
                    const info = {};
                    
                    // í˜ì´ì§€ ì œëª©ì—ì„œ ë‹¨ì§€ëª… ì¶”ì¶œ
                    const title = document.title;
                    if (title && !title.includes('ë„¤ì´ë²„í˜ì´')) {
                        info.complexName = title.split('|')[0].trim();
                    }
                    
                    // ë‹¤ì–‘í•œ ì…€ë ‰í„°ë¡œ ë‹¨ì§€ëª… ì°¾ê¸°
                    const nameSelectors = [
                        'h1.complex_title',
                        '.complex_name', 
                        '.title',
                        'h1',
                        '[class*="title"]',
                        '[class*="name"]'
                    ];
                    
                    for (const selector of nameSelectors) {
                        const element = document.querySelector(selector);
                        if (element && element.textContent.trim() && 
                            !element.textContent.includes('ê±°ë˜ë°©ì‹') &&
                            !element.textContent.includes('@naver')) {
                            info.complexName = element.textContent.trim();
                            break;
                        }
                    }
                    
                    // ì£¼ì†Œ ì •ë³´
                    const addressSelectors = [
                        '.complex_address',
                        '.address',
                        '[class*="address"]',
                        '[class*="location"]'
                    ];
                    
                    for (const selector of addressSelectors) {
                        const element = document.querySelector(selector);
                        if (element && element.textContent.trim() && 
                            !element.textContent.includes('@naver')) {
                            info.address = element.textContent.trim();
                            break;
                        }
                    }
                    
                    // ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ì •ë³´ ì¶”ì¶œ
                    const allText = document.body.textContent;
                    
                    // ì¤€ê³µë…„ë„
                    const yearPatterns = [
                        /(19|20)\\d{2}ë…„?\\s*ì¤€?ê³µ?/,
                        /(19|20)\\d{2}[\\./]\\d{1,2}/,
                        /ì¤€ê³µ\\s*(19|20)\\d{2}/
                    ];
                    
                    for (const pattern of yearPatterns) {
                        const match = allText.match(pattern);
                        if (match) {
                            info.completionYear = match[0];
                            break;
                        }
                    }
                    
                    // ì„¸ëŒ€ìˆ˜
                    const householdMatches = allText.match(/(\\d+)\\s*ì„¸ëŒ€/);
                    if (householdMatches) {
                        info.totalHouseholds = householdMatches[1];
                    }
                    
                    // ë©´ì  ì •ë³´
                    const areaMatches = allText.match(/(\\d+\\.?\\d*)ã¡/g);
                    if (areaMatches && areaMatches.length > 0) {
                        info.areas = [...new Set(areaMatches)].slice(0, 10);
                    }
                    
                    return info;
                }
            """)
            
            # URLì—ì„œ ì¶”ì¶œí•œ ID ì¶”ê°€
            basic_info['complex_id'] = complex_id
            basic_info['source_url'] = url
            
            return basic_info
            
        except Exception as e:
            print(f"âŒ ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return {'complex_id': self.extract_complex_id_from_url(url), 'source_url': url}
            
    def extract_complex_id_from_url(self, url):
        """URLì—ì„œ ë‹¨ì§€ ID ì¶”ì¶œ"""
        match = re.search(r'/complexes/(\d+)', url)
        return match.group(1) if match else 'unknown'
        
    async def extract_current_listings(self):
        """í˜„ì¬ ë§¤ë¬¼ ì •ë³´ ì¶”ì¶œ"""
        print("ğŸ  í˜„ì¬ ë§¤ë¬¼ ì •ë³´ ì¶”ì¶œ ì¤‘...")
        
        try:
            await self.page.wait_for_timeout(3000)
            
            listings = await self.page.evaluate("""
                () => {
                    const listings = [];
                    
                    // ë§¤ë¬¼ ê´€ë ¨ ì…€ë ‰í„°ë“¤
                    const listingSelectors = [
                        '.item_link',
                        '.article_item',
                        '.property_item',
                        '[class*="item"]',
                        '[class*="article"]',
                        '[class*="property"]',
                        '.list_item'
                    ];
                    
                    for (const selector of listingSelectors) {
                        const elements = document.querySelectorAll(selector);
                        
                        elements.forEach((element, index) => {
                            const text = element.textContent.trim();
                            
                            // ë¶€ë™ì‚° ê´€ë ¨ í‚¤ì›Œë“œ í•„í„°ë§
                            if (text && (
                                text.includes('ì–µ') || 
                                text.includes('ë§Œì›') ||
                                text.includes('ì „ì„¸') ||
                                text.includes('ì›”ì„¸') ||
                                text.includes('ë§¤ë§¤') ||
                                text.includes('ã¡') ||
                                text.includes('í‰') ||
                                text.includes('ì¸µ')
                            ) && text.length > 20) {  // ìµœì†Œ ê¸¸ì´ ì¡°ê±´
                                
                                // ìƒì„¸ ì •ë³´ ì¶”ì¶œ
                                const priceMatch = text.match(/(\\d+)ì–µ\\s*(\\d+)?/);
                                const monthlyMatch = text.match(/ì›”ì„¸\\s*(\\d+)/);
                                const areaMatch = text.match(/(\\d+\\.?\\d*)ã¡/);
                                const floorMatch = text.match(/(\\d+)ì¸µ/);
                                const typeMatch = text.match(/(ë§¤ë§¤|ì „ì„¸|ì›”ì„¸)/);
                                
                                listings.push({
                                    index: index,
                                    selector: selector,
                                    text: text.substring(0, 300),  // ê¸¸ì´ ì œí•œ
                                    price: priceMatch ? priceMatch[0] : null,
                                    monthly_rent: monthlyMatch ? monthlyMatch[0] : null,
                                    area: areaMatch ? areaMatch[0] : null,
                                    floor: floorMatch ? floorMatch[0] : null,
                                    deal_type: typeMatch ? typeMatch[0] : null,
                                    raw_text: text
                                });
                            }
                        });
                        
                        if (listings.length >= 30) break; // ìµœëŒ€ 30ê°œ
                    }
                    
                    // ì¤‘ë³µ ì œê±° (í…ìŠ¤íŠ¸ ê¸°ì¤€)
                    const unique_listings = [];
                    const seen_texts = new Set();
                    
                    for (const listing of listings) {
                        const short_text = listing.text.substring(0, 100);
                        if (!seen_texts.has(short_text)) {
                            seen_texts.add(short_text);
                            unique_listings.push(listing);
                        }
                    }
                    
                    return unique_listings.slice(0, 25); // ìµœëŒ€ 25ê°œ ë°˜í™˜
                }
            """)
            
            print(f"ğŸ“ ë§¤ë¬¼ ì •ë³´ {len(listings)}ê°œ ì¶”ì¶œ")
            return listings
            
        except Exception as e:
            print(f"âŒ ë§¤ë¬¼ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return []
            
    async def extract_transaction_history(self):
        """ì‹¤ê±°ë˜ê°€ ì •ë³´ ì¶”ì¶œ"""
        print("ğŸ’° ì‹¤ê±°ë˜ê°€ ì •ë³´ ì¶”ì¶œ ì¤‘...")
        
        try:
            # ì‹¤ê±°ë˜ê°€ íƒ­ í´ë¦­ ì‹œë„
            await self.page.wait_for_timeout(2000)
            
            tab_selectors = [
                'text="ì‹¤ê±°ë˜ê°€"',
                'text="ê±°ë˜"', 
                'text="ì‹¤ê±°ë˜"',
                '[class*="deal"]',
                '[class*="transaction"]'
            ]
            
            for selector in tab_selectors:
                try:
                    element = await self.page.query_selector(selector)
                    if element:
                        await element.click()
                        print(f"âœ… ì‹¤ê±°ë˜ê°€ íƒ­ í´ë¦­ ì„±ê³µ")
                        await self.page.wait_for_timeout(3000)
                        break
                except:
                    continue
            
            # 60ê°œì›” ë°ì´í„° ì„ íƒ ì‹œë„
            print("â³ 60ê°œì›” ë°ì´í„° ì„ íƒ ì‹œë„...")
            try:
                # "ê¸°ê°„" ë²„íŠ¼ í´ë¦­ (ì •í™•í•œ ì…€ë ‰í„°ëŠ” ì›¹í˜ì´ì§€ êµ¬ì¡°ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
                await self.page.click('button:has-text("ê¸°ê°„")')
                await self.page.wait_for_timeout(1000)
                # "60ê°œì›”" ì˜µì…˜ í´ë¦­ (ì •í™•í•œ ì…€ë ‰í„°ëŠ” ì›¹í˜ì´ì§€ êµ¬ì¡°ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
                await self.page.click('li:has-text("60ê°œì›”")')
                print("âœ… 60ê°œì›” ê¸°ê°„ ì„ íƒ ì„±ê³µ")
                await self.page.wait_for_timeout(3000) # ë°ì´í„° ë¡œë“œë¥¼ ìœ„í•´ ëŒ€ê¸°
            except Exception as e:
                print(f"âš ï¸ 60ê°œì›” ê¸°ê°„ ì„ íƒ ì‹¤íŒ¨ (ìˆ˜ë™ ì„ íƒ í•„ìš”í•  ìˆ˜ ìˆìŒ): {e}")
                # ì‹¤íŒ¨ ì‹œ, ë‹¤ìŒ ë¡œì§ìœ¼ë¡œ ì§„í–‰ (ëª¨ë“  ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í•  ìˆ˜ ìˆìŒ)
                pass
                    
            # ì‹¤ê±°ë˜ê°€ ë°ì´í„° ì¶”ì¶œ
            transactions = await self.page.evaluate("""
                () => {
                    const transactions = [];
                    const text = document.body.textContent;
                    
                    // ì‹¤ê±°ë˜ê°€ íŒ¨í„´ë“¤
                    const patterns = [
                        // ë‚ ì§œ + ê°€ê²© íŒ¨í„´
                        /\\d{4}[\\.\\/]\\d{1,2}[\\.\\/]\\d{1,2}.*?(\\d+)ì–µ\\s*(\\d+)?/g,
                        // ê°€ê²© + ë©´ì  íŒ¨í„´  
                        /(\\d+)ì–µ\\s*(\\d+)?.*?(\\d+\\.?\\d*)ã¡/g,
                        // ê±°ë˜ìœ í˜• + ê°€ê²©
                        /(ë§¤ë§¤|ì „ì„¸).*?(\\d+)ì–µ/g,
                        // ì¸µìˆ˜ + ê°€ê²©
                        /(\\d+)ì¸µ.*?(\\d+)ì–µ/g
                    ];
                    
                    patterns.forEach((pattern, patternIndex) => {
                        let match;
                        // count < 15 ì œí•œ ì œê±°
                        while ((match = pattern.exec(text)) !== null) {
                            transactions.push({
                                pattern_type: patternIndex,
                                match_text: match[0],
                                context: text.substring(
                                    Math.max(0, match.index - 100), 
                                    Math.min(text.length, match.index + 200)
                                )
                            });
                            // count++; // ì œí•œì´ ì—†ìœ¼ë¯€ë¡œ í•„ìš” ì—†ìŒ
                        }
                    });
                    
                    // í…Œì´ë¸” ë°ì´í„° ì¶”ì¶œ
                    const tables = document.querySelectorAll('table, .table, [class*="table"]');
                    tables.forEach((table, tableIndex) => {
                        const tableText = table.textContent;
                        if ((tableText.includes('ì–µ') || tableText.includes('ë§Œì›')) && 
                            tableText.length > 50) {
                            transactions.push({
                                type: 'table',
                                table_index: tableIndex,
                                content: tableText.substring(0, 800)
                            });
                        }
                    });
                    
                    return transactions; // slice(0, 40) ì œí•œ ì œê±°
                }
            """)
            
            print(f"ğŸ’¸ ì‹¤ê±°ë˜ê°€ ì •ë³´ {len(transactions)}ê°œ ì¶”ì¶œ")
            return transactions
            
        except Exception as e:
            print(f"âŒ ì‹¤ê±°ë˜ê°€ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return []
            
    async def extract_comprehensive_data(self, url):
        """ì¢…í•© ë°ì´í„° ì¶”ì¶œ"""
        print("ğŸ“Š ì¢…í•© ë°ì´í„° ì¶”ì¶œ ì¤‘...")
        
        try:
            # ìŠ¤í¬ë¦°ìƒ· ì €ì¥
            if self.screenshot:
                complex_id = self.extract_complex_id_from_url(url)
                screenshot_path = f"data/output/screenshot_{complex_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
                Path("data/output").mkdir(parents=True, exist_ok=True)
                await self.page.screenshot(path=screenshot_path, full_page=True)
                print(f"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {screenshot_path}")
            else:
                screenshot_path = None
                
            # ìƒì„¸ ì •ë³´ ì¶”ì¶œ
            detailed_info = await self.page.evaluate("""
                () => {
                    const info = {
                        page_title: document.title,
                        url: window.location.href,
                        extracted_at: new Date().toISOString()
                    };
                    
                    const fullText = document.body.textContent;
                    
                    // ëª¨ë“  ê°€ê²© ì •ë³´ ì¶”ì¶œ
                    const pricePatterns = [
                        /\\d+ì–µ\\s*\\d*ì²œ?ë§Œ?ì›?/g,
                        /\\d+ì²œë§Œì›/g,
                        /\\d+ë§Œì›/g,
                        /ì›”ì„¸\\s*\\d+ë§Œ?ì›?/g,
                        /ì „ì„¸\\s*\\d+ì–µ?\\d*ì²œ?ë§Œ?ì›?/g,
                        /ë§¤ë§¤\\s*\\d+ì–µ?\\d*ì²œ?ë§Œ?ì›?/g
                    ];
                    
                    info.all_prices = [];
                    pricePatterns.forEach(pattern => {
                        const matches = fullText.match(pattern) || [];
                        info.all_prices.push(...matches);
                    });
                    
                    // ì¤‘ë³µ ì œê±°
                    info.all_prices = [...new Set(info.all_prices)];
                    
                    // ë©´ì  ì •ë³´
                    const areaMatches = fullText.match(/\\d+\\.?\\d*ã¡/g) || [];
                    info.areas = [...new Set(areaMatches)];
                    
                    // ì¸µìˆ˜ ì •ë³´
                    const floorMatches = fullText.match(/\\d+ì¸µ/g) || [];
                    info.floors = [...new Set(floorMatches)].slice(0, 15);
                    
                    // ê±°ë˜ìœ í˜•
                    const dealMatches = fullText.match(/(ë§¤ë§¤|ì „ì„¸|ì›”ì„¸)/g) || [];
                    info.deal_types = [...new Set(dealMatches)];
                    
                    return info;
                }
            """)
            
            detailed_info['screenshot_path'] = screenshot_path
            return detailed_info
            
        except Exception as e:
            print(f"âŒ ì¢…í•© ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return {'screenshot_path': None}
            
    def analyze_price_data(self, listings, transactions, detailed_info):
        """ê°€ê²© ë°ì´í„° ë¶„ì„"""
        analysis = {
            'listing_prices': [],
            'transaction_prices': [],
            'price_range': {'min': 0, 'max': 0},
            'avg_price': 0,
            'deal_type_count': {},
            'area_price_ratio': []
        }
        
        try:
            # ë§¤ë¬¼ ê°€ê²© ë¶„ì„
            for listing in listings:
                if listing.get('price'):
                    price_text = listing['price']
                    # ì–µ ë‹¨ìœ„ë¡œ ë³€í™˜
                    match = re.search(r'(\d+)ì–µ\s*(\d+)?', price_text)
                    if match:
                        price = int(match.group(1)) * 10000  # ë§Œì› ë‹¨ìœ„
                        if match.group(2):
                            price += int(match.group(2)) * 1000
                        analysis['listing_prices'].append(price)
                        
                # ê±°ë˜ìœ í˜• ì¹´ìš´íŠ¸
                deal_type = listing.get('deal_type')
                if deal_type:
                    analysis['deal_type_count'][deal_type] = analysis['deal_type_count'].get(deal_type, 0) + 1
                    
            # ê°€ê²© ë²”ìœ„ ê³„ì‚°
            if analysis['listing_prices']:
                analysis['price_range']['min'] = min(analysis['listing_prices'])
                analysis['price_range']['max'] = max(analysis['listing_prices'])
                analysis['avg_price'] = sum(analysis['listing_prices']) / len(analysis['listing_prices'])
                
        except Exception as e:
            print(f"âš ï¸ ê°€ê²© ë¶„ì„ ì˜¤ë¥˜: {e}")
            
        return analysis
        
    async def save_complex_data(self, complex_id, basic_info, listings, transactions, detailed_info, analysis):
        """ë‹¨ì§€ ë°ì´í„° ì €ì¥"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        Path("data/output").mkdir(parents=True, exist_ok=True)
        
        # ì¢…í•© ë°ì´í„° êµ¬ì„±
        comprehensive_data = {
            'complex_basic_info': basic_info,
            'current_listings': listings,
            'transaction_history': transactions,
            'detailed_analysis': detailed_info,
            'price_analysis': analysis,
            'crawl_metadata': {
                'complex_id': complex_id,
                'crawled_at': datetime.now().isoformat(),
                'method': 'playwright_mcp_modular',
                'total_listings': len(listings),
                'total_transactions': len(transactions),
                'total_prices': len(detailed_info.get('all_prices', []))
            }
        }
        
        # JSON íŒŒì¼ ì €ì¥
        json_file = f"data/output/complex_{complex_id}_comprehensive_{timestamp}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(comprehensive_data, f, ensure_ascii=False, indent=2)
            
        # CSV ìš”ì•½ ì €ì¥
        csv_file = f"data/output/complex_{complex_id}_summary_{timestamp}.csv"
        with open(csv_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow([
                'complex_id', 'complex_name', 'address', 'completion_year', 'households',
                'total_listings', 'total_transactions', 'price_min', 'price_max', 'price_avg',
                'deal_types', 'areas_count', 'floors_count', 'source_url', 'screenshot_path'
            ])
            
            deal_types_str = ', '.join(analysis['deal_type_count'].keys()) if analysis['deal_type_count'] else 'ì •ë³´ì—†ìŒ'
            
            writer.writerow([
                complex_id,
                basic_info.get('complexName', 'ì •ë³´ì—†ìŒ'),
                basic_info.get('address', 'ì •ë³´ì—†ìŒ'),
                basic_info.get('completionYear', 'ì •ë³´ì—†ìŒ'),
                basic_info.get('totalHouseholds', 'ì •ë³´ì—†ìŒ'),
                len(listings),
                len(transactions),
                analysis['price_range']['min'] if analysis['listing_prices'] else 0,
                analysis['price_range']['max'] if analysis['listing_prices'] else 0,
                round(analysis['avg_price']) if analysis['avg_price'] > 0 else 0,
                deal_types_str,
                len(detailed_info.get('areas', [])),
                len(detailed_info.get('floors', [])),
                basic_info.get('source_url', ''),
                detailed_info.get('screenshot_path', '')
            ])
            
        return {
            'json_file': json_file,
            'csv_file': csv_file,
            'screenshot': detailed_info.get('screenshot_path')
        }
        
    async def crawl_complex(self, complex_url, complex_name=None):
        """
        ë‹¨ì§€ í¬ë¡¤ë§ ë©”ì¸ í•¨ìˆ˜
        
        Args:
            complex_url (str): ë„¤ì´ë²„ ë¶€ë™ì‚° ë‹¨ì§€ URL
            complex_name (str): ë‹¨ì§€ëª… (ì„ íƒì‚¬í•­)
            
        Returns:
            dict: í¬ë¡¤ë§ ê²°ê³¼ ë° íŒŒì¼ ê²½ë¡œ
        """
        try:
            await self.init_browser()
            
            complex_id = self.extract_complex_id_from_url(complex_url)
            display_name = complex_name or f"ë‹¨ì§€_{complex_id}"
            
            print(f"\nğŸ  {display_name} í¬ë¡¤ë§ ì‹œì‘!")
            print(f"ğŸ¯ URL: {complex_url}")
            
            # 1. ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
            basic_info = await self.extract_complex_basic_info(complex_url)
            
            # 2. í˜„ì¬ ë§¤ë¬¼ ì¶”ì¶œ
            listings = await self.extract_current_listings()
            
            # 3. ì‹¤ê±°ë˜ê°€ ì¶”ì¶œ
            transactions = await self.extract_transaction_history()
            
            # 4. ì¢…í•© ë°ì´í„° ì¶”ì¶œ
            detailed_info = await self.extract_comprehensive_data(complex_url)
            
            # 5. ê°€ê²© ë¶„ì„
            analysis = self.analyze_price_data(listings, transactions, detailed_info)
            
            # 6. ë°ì´í„° ì €ì¥
            file_paths = await self.save_complex_data(
                complex_id, basic_info, listings, transactions, detailed_info, analysis
            )
            
            # 7. ê²°ê³¼ ìš”ì•½
            print(f"\nğŸ‰ {display_name} í¬ë¡¤ë§ ì™„ë£Œ!")
            print(f"ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼:")
            print(f"  ğŸ¢ ë‹¨ì§€ID: {complex_id}")
            print(f"  ğŸ  ë§¤ë¬¼: {len(listings)}ê°œ")
            print(f"  ğŸ’° ê±°ë˜ê¸°ë¡: {len(transactions)}ê°œ")
            print(f"  ğŸ“‹ ê°€ê²©ì •ë³´: {len(detailed_info.get('all_prices', []))}ê°œ")
            
            if analysis['listing_prices']:
                print(f"  ğŸ’µ ê°€ê²©ë²”ìœ„: {analysis['price_range']['min']:,}~{analysis['price_range']['max']:,}ë§Œì›")
                print(f"  ğŸ“ˆ í‰ê· ê°€ê²©: {analysis['avg_price']:,.0f}ë§Œì›")
                
            if analysis['deal_type_count']:
                print(f"  ğŸ·ï¸ ê±°ë˜ìœ í˜•: {', '.join(analysis['deal_type_count'].keys())}")
                
            return {
                'success': True,
                'complex_id': complex_id,
                'complex_name': basic_info.get('complexName', display_name),
                'data_summary': {
                    'listings_count': len(listings),
                    'transactions_count': len(transactions),
                    'prices_count': len(detailed_info.get('all_prices', [])),
                    'price_range': analysis['price_range'],
                    'avg_price': analysis['avg_price']
                },
                'files': file_paths
            }
            
        except Exception as e:
            print(f"âŒ {display_name} í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return {
                'success': False,
                'error': str(e),
                'complex_id': self.extract_complex_id_from_url(complex_url)
            }
            
        finally:
            if self.browser:
                await self.browser.close()

# ì‚¬ìš© ì˜ˆì‹œ í•¨ìˆ˜ë“¤
async def crawl_single_complex(url, name=None, headless=False):
    """ë‹¨ì¼ ë‹¨ì§€ í¬ë¡¤ë§"""
    crawler = NaverComplexCrawler(headless=headless, screenshot=True)
    return await crawler.crawl_complex(url, name)

async def crawl_multiple_complexes(complex_list, headless=False):
    """
    ì—¬ëŸ¬ ë‹¨ì§€ ìˆœì°¨ í¬ë¡¤ë§
    
    Args:
        complex_list (list): [{'url': 'URL', 'name': 'ë‹¨ì§€ëª…'}, ...] í˜•ì‹ì˜ ë¦¬ìŠ¤íŠ¸
        headless (bool): í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ ì—¬ë¶€
        
    Returns:
        list: ê° ë‹¨ì§€ë³„ í¬ë¡¤ë§ ê²°ê³¼
    """
    results = []
    
    for i, complex_info in enumerate(complex_list, 1):
        print(f"\nğŸ”„ [{i}/{len(complex_list)}] í¬ë¡¤ë§ ì§„í–‰ ì¤‘...")
        
        crawler = NaverComplexCrawler(headless=headless, screenshot=True)
        result = await crawler.crawl_complex(
            complex_info['url'], 
            complex_info.get('name')
        )
        results.append(result)
        
        # ìš”ì²­ ê°„ê²© (ë„ˆë¬´ ë¹ ë¥¸ ì—°ì† ìš”ì²­ ë°©ì§€)
        if i < len(complex_list):
            print("â±ï¸ ì ì‹œ ëŒ€ê¸° ì¤‘...")
            await asyncio.sleep(5)
            
    return results

# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
async def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    # ì •ë“ í•œì§„6ì°¨ í…ŒìŠ¤íŠ¸
    test_url = "https://new.land.naver.com/complexes/2592?ms=37.36286,127.115578,17&a=APT:ABYG:JGC:PRE&e=RETAIL"
    
    print("ğŸš€ ë„¤ì´ë²„ ë¶€ë™ì‚° ëª¨ë“ˆí™” í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸")
    result = await crawl_single_complex(test_url, "ì •ë“ í•œì§„6ì°¨", headless=False)
    
    if result['success']:
        print(f"\nâœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        print(f"ğŸ“„ ìƒì„±ëœ íŒŒì¼:")
        for key, path in result['files'].items():
            if path:
                print(f"  {key}: {path}")
    else:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {result['error']}")

if __name__ == "__main__":
    asyncio.run(main())
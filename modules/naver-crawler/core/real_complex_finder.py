"""
ì‹¤ì œ ì „êµ­ ì•„íŒŒíŠ¸ ë‹¨ì§€ ID ìˆ˜ì§‘ ì‹œìŠ¤í…œ
ë„¤ì´ë²„ ë¶€ë™ì‚° API ë° ì‚¬ì´íŠ¸ë§µ í™œìš©
"""

import asyncio
import requests
import json
import time
import logging
from datetime import datetime
from typing import List, Dict, Set
import sqlite3
from pathlib import Path
import re
from playwright.async_api import async_playwright
import random

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class RealComplexFinder:
    """ì‹¤ì œ ì „êµ­ ì•„íŒŒíŠ¸ ë‹¨ì§€ ID ìˆ˜ì§‘ê¸°"""
    
    def __init__(self):
        self.db_path = 'data/real_complexes.db'
        self.complex_ids = set()
        self.init_database()
        
    def init_database(self):
        """ì‹¤ì œ ë‹¨ì§€ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        Path(self.db_path).parent.mkdir(parents=True, exist_ok=True)
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS real_complexes (
                complex_id TEXT PRIMARY KEY,
                complex_name TEXT,
                address TEXT,
                coordinates TEXT,
                building_count INTEGER,
                household_count INTEGER,
                completion_year TEXT,
                found_method TEXT,
                source_url TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
        logger.info(f"ì‹¤ì œ ë‹¨ì§€ DB ì´ˆê¸°í™”: {self.db_path}")
        
    async def find_complexes_by_sequential_id(self, start_id: int = 1, end_id: int = 100000):
        """ìˆœì°¨ì  IDë¡œ ë‹¨ì§€ ë°œê²¬ (1~100000)"""
        logger.info(f"ğŸ” ìˆœì°¨ì  ID ìŠ¤ìº” ì‹œì‘: {start_id} ~ {end_id}")
        
        found_count = 0
        total_checked = 0
        
        async with async_playwright() as playwright:
            browser = await playwright.chromium.launch(headless=True)
            
            # ë™ì‹œì— ì—¬ëŸ¬ í˜ì´ì§€ë¡œ ë³‘ë ¬ ì²˜ë¦¬
            tasks = []
            semaphore = asyncio.Semaphore(5)  # 5ê°œ ë™ì‹œ ìš”ì²­
            
            async def check_complex_id(complex_id):
                nonlocal found_count, total_checked
                
                async with semaphore:
                    try:
                        page = await browser.new_page()
                        url = f"https://new.land.naver.com/complexes/{complex_id}"
                        
                        response = await page.goto(url, timeout=10000)
                        
                        if response and response.status == 200:
                            # í˜ì´ì§€ ë‚´ìš© í™•ì¸
                            title = await page.title()
                            
                            # ìœ íš¨í•œ ë‹¨ì§€ì¸ì§€ í™•ì¸
                            if "ë„¤ì´ë²„í˜ì´ ë¶€ë™ì‚°" in title and "404" not in title:
                                # ë‹¨ì§€ ì •ë³´ ì¶”ì¶œ
                                complex_info = await page.evaluate("""
                                    () => {
                                        const info = {};
                                        
                                        // ë‹¨ì§€ëª… ì¶”ì¶œ
                                        const titleElement = document.querySelector('h1, .complex_title, .title');
                                        if (titleElement) {
                                            info.name = titleElement.textContent.trim();
                                        }
                                        
                                        // ì£¼ì†Œ ì¶”ì¶œ
                                        const addressElement = document.querySelector('.address, .location');
                                        if (addressElement) {
                                            info.address = addressElement.textContent.trim();
                                        }
                                        
                                        // ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
                                        const text = document.body.textContent;
                                        
                                        // ì„¸ëŒ€ìˆ˜ ì¶”ì¶œ
                                        const householdMatch = text.match(/(\\d+)\\s*ì„¸ëŒ€/);
                                        if (householdMatch) {
                                            info.household_count = parseInt(householdMatch[1]);
                                        }
                                        
                                        // ì¤€ê³µë…„ë„ ì¶”ì¶œ
                                        const yearMatch = text.match(/(19|20)\\d{2}ë…„/);
                                        if (yearMatch) {
                                            info.completion_year = yearMatch[0];
                                        }
                                        
                                        return info;
                                    }
                                """)
                                
                                if complex_info.get('name'):
                                    self.save_complex_info(complex_id, complex_info, 'sequential_scan', url)
                                    found_count += 1
                                    logger.info(f"âœ… ë°œê²¬: {complex_id} - {complex_info.get('name', 'Unknown')}")
                                    
                        await page.close()
                        total_checked += 1
                        
                        if total_checked % 100 == 0:
                            logger.info(f"ğŸ“Š ì§„í–‰ë¥ : {total_checked}ê°œ í™•ì¸, {found_count}ê°œ ë°œê²¬")
                            
                        # ìš”ì²­ ê°„ê²© ì¡°ì ˆ
                        await asyncio.sleep(random.uniform(0.1, 0.5))
                        
                    except Exception as e:
                        await page.close()
                        
            # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
            batch_size = 50
            for i in range(start_id, end_id + 1, batch_size):
                batch_end = min(i + batch_size - 1, end_id)
                batch_tasks = [check_complex_id(cid) for cid in range(i, batch_end + 1)]
                
                await asyncio.gather(*batch_tasks, return_exceptions=True)
                
                # ë°°ì¹˜ ê°„ ëŒ€ê¸°
                await asyncio.sleep(random.uniform(2, 5))
                
            await browser.close()
            
        logger.info(f"ğŸ‰ ìˆœì°¨ì  ìŠ¤ìº” ì™„ë£Œ: {found_count}ê°œ ë‹¨ì§€ ë°œê²¬")
        return found_count
        
    def save_complex_info(self, complex_id: int, info: Dict, method: str, url: str):
        """ë‹¨ì§€ ì •ë³´ ì €ì¥"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT OR REPLACE INTO real_complexes
            (complex_id, complex_name, address, household_count, completion_year, found_method, source_url)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        ''', (
            str(complex_id),
            info.get('name', ''),
            info.get('address', ''),
            info.get('household_count', 0),
            info.get('completion_year', ''),
            method,
            url
        ))
        
        conn.commit()
        conn.close()
        
    async def find_complexes_by_sitemap(self):
        """ë„¤ì´ë²„ ì‚¬ì´íŠ¸ë§µì—ì„œ ë‹¨ì§€ ID ì¶”ì¶œ"""
        logger.info("ğŸ—ºï¸ ë„¤ì´ë²„ ì‚¬ì´íŠ¸ë§µì—ì„œ ë‹¨ì§€ ID ìˆ˜ì§‘ ì‹œì‘")
        
        sitemap_urls = [
            "https://new.land.naver.com/sitemap.xml",
            "https://new.land.naver.com/robots.txt"
        ]
        
        complex_ids = set()
        
        for url in sitemap_urls:
            try:
                response = requests.get(url, timeout=10)
                if response.status_code == 200:
                    content = response.text
                    
                    # complexes/ìˆ«ì íŒ¨í„´ ì°¾ê¸°
                    matches = re.findall(r'complexes/(\d+)', content)
                    for match in matches:
                        complex_ids.add(int(match))
                        
            except Exception as e:
                logger.error(f"ì‚¬ì´íŠ¸ë§µ ì²˜ë¦¬ ì˜¤ë¥˜: {url} - {e}")
                
        logger.info(f"âœ… ì‚¬ì´íŠ¸ë§µì—ì„œ {len(complex_ids)}ê°œ ë‹¨ì§€ ID ë°œê²¬")
        return list(complex_ids)
        
    def find_complexes_by_pattern_analysis(self) -> List[int]:
        """ê¸°ì¡´ ì„±ê³µí•œ IDë“¤ì˜ íŒ¨í„´ ë¶„ì„"""
        logger.info("ğŸ“Š ê¸°ì¡´ ì„±ê³µ ID íŒ¨í„´ ë¶„ì„")
        
        # ê¸°ì¡´ í¬ë¡¤ë§ì—ì„œ ì„±ê³µí•œ IDë“¤
        successful_ids = [
            1168, 1418, 2592, 4568, 105, 1309, 934, 856, 1205, 1876,
            3847, 2845, 3921, 1734, 2654, 3456, 4123, 2789, 3567, 4234,
            567, 789, 1023, 1456, 2345, 3678, 4567, 1789, 2890, 3901
        ]
        
        # íŒ¨í„´ ë¶„ì„
        candidate_ids = []
        
        # 1. ì—°ì†ëœ ë²”ìœ„ ì¶”ì •
        for base_id in successful_ids:
            # ê¸°ì¤€ ID ì£¼ë³€ Â±50 ë²”ìœ„
            for offset in range(-50, 51):
                candidate_id = base_id + offset
                if candidate_id > 0 and candidate_id not in successful_ids:
                    candidate_ids.append(candidate_id)
                    
        # 2. íŠ¹ì • íŒ¨í„´ (1000ì˜ ë°°ìˆ˜, 500ì˜ ë°°ìˆ˜ ë“±)
        for i in range(1, 10000):
            if i % 100 == 0:  # 100ì˜ ë°°ìˆ˜
                candidate_ids.append(i)
            if i % 500 == 0:  # 500ì˜ ë°°ìˆ˜
                candidate_ids.append(i)
                
        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        candidate_ids = sorted(list(set(candidate_ids)))
        
        logger.info(f"âœ… íŒ¨í„´ ë¶„ì„ìœ¼ë¡œ {len(candidate_ids)}ê°œ í›„ë³´ ID ìƒì„±")
        return candidate_ids
        
    async def run_comprehensive_discovery(self):
        """ì¢…í•©ì ì¸ ë‹¨ì§€ ë°œê²¬ ì‹¤í–‰"""
        logger.info("ğŸš€ ì¢…í•©ì ì¸ ì „êµ­ ë‹¨ì§€ ë°œê²¬ ì‹œì‘")
        
        total_found = 0
        
        # 1. ì‚¬ì´íŠ¸ë§µ ë¶„ì„
        sitemap_ids = await self.find_complexes_by_sitemap()
        total_found += len(sitemap_ids)
        
        # 2. íŒ¨í„´ ë¶„ì„ ê¸°ë°˜ íƒìƒ‰
        pattern_ids = self.find_complexes_by_pattern_analysis()
        
        # 3. ìˆœì°¨ì  ìŠ¤ìº” (ì‘ì€ ë²”ìœ„ë¶€í„°)
        logger.info("ğŸ” ìˆœì°¨ì  ìŠ¤ìº” ì‹œì‘ (1~5000)")
        sequential_found = await self.find_complexes_by_sequential_id(1, 5000)
        total_found += sequential_found
        
        # 4. í†µê³„ ì¶œë ¥
        stats = self.get_discovery_stats()
        logger.info(f"ğŸ‰ ì¢…í•© ë°œê²¬ ì™„ë£Œ: {stats['total_complexes']}ê°œ ë‹¨ì§€")
        
        return stats
        
    def get_discovery_stats(self) -> Dict:
        """ë°œê²¬ í†µê³„ ì¡°íšŒ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('SELECT COUNT(*) FROM real_complexes')
        total_count = cursor.fetchone()[0]
        
        cursor.execute('''
            SELECT found_method, COUNT(*) as count
            FROM real_complexes
            GROUP BY found_method
        ''')
        method_stats = dict(cursor.fetchall())
        
        cursor.execute('SELECT complex_id, complex_name, address FROM real_complexes LIMIT 10')
        sample_complexes = cursor.fetchall()
        
        conn.close()
        
        return {
            'total_complexes': total_count,
            'method_stats': method_stats,
            'sample_complexes': sample_complexes
        }
        
    def get_all_discovered_ids(self) -> List[str]:
        """ë°œê²¬ëœ ëª¨ë“  ë‹¨ì§€ ID ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('SELECT complex_id FROM real_complexes ORDER BY complex_id')
        ids = [row[0] for row in cursor.fetchall()]
        
        conn.close()
        return ids

# ì‹¤í–‰ í•¨ìˆ˜
async def run_real_discovery():
    """ì‹¤ì œ ë‹¨ì§€ ë°œê²¬ ì‹¤í–‰"""
    finder = RealComplexFinder()
    
    # ì¢…í•©ì ì¸ ë°œê²¬ ì‹¤í–‰
    stats = await finder.run_comprehensive_discovery()
    
    print(f"\nğŸ¯ ì‹¤ì œ ë‹¨ì§€ ë°œê²¬ ê²°ê³¼:")
    print(f"  ğŸ“Š ì´ ë°œê²¬ ë‹¨ì§€: {stats['total_complexes']}ê°œ")
    print(f"  ğŸ” ë°œê²¬ ë°©ë²•ë³„ í†µê³„: {stats['method_stats']}")
    
    print(f"\nğŸ“‹ ë°œê²¬ëœ ë‹¨ì§€ ì˜ˆì‹œ:")
    for complex_id, name, address in stats['sample_complexes']:
        print(f"  {complex_id}: {name} - {address}")
        
    # ë°œê²¬ëœ IDë“¤ì„ ê¸°ì¡´ í¬ë¡¤ë§ ì‹œìŠ¤í…œì— ì‚¬ìš© ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë°˜í™˜
    all_ids = finder.get_all_discovered_ids()
    print(f"\nğŸ”— í¬ë¡¤ë§ ê°€ëŠ¥í•œ ë‹¨ì§€ ID: {len(all_ids)}ê°œ")
    
    return all_ids

if __name__ == "__main__":
    asyncio.run(run_real_discovery())
알겠습니다, 개발자님. 현재 분산된 데이터 소스를 통합하여 원하시는 지도 기반 부동산 정보 서비스를 구현하기 위한 데이터베이스 설계 및 통합 전략을 도출할 수 있는, 매우 구체적이고 강력한 프롬프트를 작성해 드리겠습니다.

이 프롬프트는 AI(저와 같은)에게 제공했을 때, 개발자님이 바로 실행에 옮길 수 있는 구체적인 SQL 스키마, 데이터 처리 로직, API 설계안을 얻을 수 있도록 구성되었습니다.

---

### **AI 모델을 위한 최종 프롬프트**

아래 내용을 복사하여 AI 모델에 입력하시면 됩니다.

```text
너는 부동산 데이터 플랫폼을 전문적으로 설계하는 데이터 아키텍트이자 수석 풀스택 개발자(Principal Full-Stack Developer)다. 나는 현재 여러 소스에 흩어져 있는 부동산 데이터를 통합하여 최종 사용자에게 일관된 정보를 제공하는 데 어려움을 겪고 있다. 나의 목표는 지도 기반 서비스에 최적화된 통합 데이터베이스를 설계하고, 기존의 분산된 데이터를 이 새로운 데이터베이스로 이전 및 통합(ETL)하기 위한 구체적인 실행 계획을 수립하는 것이다.

### 1. 프로젝트 목표 및 요구사항

- **최종 목표:** 사용자가 지도를 움직이면 해당 지역의 아파트 단지들이 마커로 표시된다. 마커를 클릭하면 해당 아파트의 상세 정보(단지명, 건축년도, 세대수 등)와 함께, **최신 실거래가**와 **현재 등록된 매물 호가**를 평형별로 구분하여 한눈에 볼 수 있는 UI를 구현한다.
- **핵심 과제:** 여러 데이터베이스에 파편화된 데이터를 논리적으로 통합하여, 단일 API 호출 또는 최소한의 호출로 지도에 필요한 모든 정보를 효율적으로 제공할 수 있는 백엔드 시스템을 구축한다.

### 2. 현재 데이터 소스 현황 (As-Is)

현재 총 5개의 데이터 소스가 있으며, 데이터 간 중복 및 불일치가 존재한다.

| # | 데이터 소스 명칭 | 저장소 | 주요 테이블/데이터 | 핵심 데이터 내용 | 레코드 수 | 상태 |
|---|---|---|---|---|---|---|
| 1 | **MOLIT 정부 데이터** | 로컬 SQLite | `apartment_transactions` | 5년간의 전국 아파트 실거래가 (매매, 전세, 월세) | 977,388건 | 완료 |
| 2 | **네이버부동산 크롤링** | 로컬 SQLite | `apartment_complexes` | 매물 호가 (매매, 전세, 월세), 단지 상세 정보 | 875개 단지 | 완료 |
| 3 | **Supabase Project 1** | 클라우드 | `apartment_complexes`, `apartment_transactions` | 2번과 1번 데이터의 통합 시도 버전 (데이터 엉킴 발생) | 1,139개 단지, 70,500건 | 활성 (문제 있음) |
| 4 | **Supabase Project 2** | 클라우드 | `apt_master_info` | 전국의 아파트 단지 마스터 정보 (단지명, 건축년도, 주소, 좌표) | 46,539개 단지 | 활성 |
| 5 | **PostgreSQL** | 클라우드 | (웹 플랫폼용) | 현재 웹 애플리케이션의 주 데이터베이스 | N/A | 활성 |

### 3. 내가 요청하는 구체적인 산출물

위의 목표와 현황을 바탕으로, 아래의 4가지 항목에 대한 구체적이고 실행 가능한 계획을 제시해줘.

**Task 1: 통합 데이터베이스 스키마 설계**
- 최종 목표(지도 기반 서비스)에 최적화된 새로운 PostgreSQL 데이터베이스 스키마를 설계해줘.
- 아래 두 가지 핵심 테이블에 대한 `CREATE TABLE` SQL 구문을 작성해줘.
    1.  `unified_complexes`: 모든 아파트 단지 정보를 통합 관리할 마스터 테이블.
        - **필수 컬럼 제안:** `complex_id` (PK, 고유 식별자), `complex_name` (단지명), `address` (표준화된 주소), `latitude` (위도), `longitude` (경도), `built_year` (건축년도), `total_households` (총 세대수), `created_at`, `updated_at` 등.
    2.  `unified_prices`: 실거래가와 매물 호가를 모두 저장할 통합 가격 정보 테이블.
        - **필수 컬럼 제안:** `price_id` (PK), `complex_id` (FK), `price_type` ('DEAL' 또는 'OFFER'), `trade_type` ('SALE' 또는 'RENT'), `price` (가격), `area_m2` (면적), `floor` (층), `contract_date` (계약일 또는 등록일), `source_id` (원본 데이터 식별자) 등.
- 각 컬럼의 데이터 타입과 제약 조건(Not Null, Unique 등)을 명시하고, 두 테이블 간의 관계(Foreign Key)를 명확히 정의해줘.

**Task 2: 데이터 통합 및 이전(ETL) 전략**
- 5개의 분산된 데이터 소스에서 데이터를 추출(Extract), 변환(Transform), 그리고 새로운 통합 DB에 적재(Load)하기 위한 단계별 실행 계획을 제시해줘.
- **가장 중요한 '개체 식별(Entity Resolution)' 문제 해결 방안:** 서로 다른 데이터 소스에 있는 동일한 아파트 단지를 어떻게 식별할 것인지 구체적인 방법을 제시해줘. (예: 주소 정규화 후 매칭, 단지명과 건축년도 조합으로 매칭 등)
- **데이터 매핑 테이블:** 기존 테이블(예: `molit.apartment_transactions`, `naver.apartment_complexes`)의 컬럼들이 새로운 통합 테이블(`unified_complexes`, `unified_prices`)의 어떤 컬럼으로 매핑되는지 명확하게 보여주는 표를 작성해줘.
- 이 ETL 과정을 수행하기 위한 Python 스크립트의 의사코드(Pseudocode) 또는 핵심 로직을 작성해줘. (Pandas 라이브러리 사용을 가정)

**Task 3: API 엔드포인트 설계**
- 통합된 데이터를 프론트엔드(React)에 효율적으로 전달하기 위한 RESTful API 엔드포인트를 설계해줘.
- **핵심 API:** 지도 화면의 현재 보이는 영역(Bounding Box) 내의 아파트 단지 정보와 각 단지별 최신 가격 정보를 반환하는 API.
    - 예: `GET /api/v1/complexes/by-location?sw_lat=...&sw_lng=...&ne_lat=...&ne_lng=...`
- 위 API가 반환해야 할 JSON 데이터 구조의 예시를 보여줘. JSON에는 단지 정보와 그에 속한 가격 정보(실거래가, 호가)가 함께 포함되어야 한다.

**Task 4: 기술 스택 및 실행 순서 제안**
- 현재 기술 스택(Python, Node.js, PostgreSQL)을 고려할 때, 이 ETL 파이프라인과 API 서버를 구축하기 위한 최적의 도구와 라이브러리를 추천해줘.
- 이 모든 작업을 어떤 순서로 진행해야 할지, 우선순위가 포함된 실행 로드맵을 제시해줘. (예: 1. 스키마 확정 -> 2. ETL 스크립트 개발 -> 3. 데이터 마이그레이션 -> 4. API 개발 -> 5. 프론트엔드 연동)
```

---

### **이 프롬프트가 왜 효과적인가요?**

1.  **명확한 역할 부여 (Persona):** "너는 ... 데이터 아키텍트이자 수석 개발자다"라고 역할을 부여함으로써, AI가 전문가의 관점에서 체계적이고 깊이 있는 답변을 생성하도록 유도합니다.
2.  **구체적인 목표 설정:** "지도 기반 서비스"와 "실거래가와 호가를 함께 표시"라는 명확한 최종 목표를 제시하여, AI가 단순히 데이터를 합치는 것이 아니라 **목적에 맞는** 결과물을 설계하도록 합니다.
3.  **상세한 현황 정보 제공 (Context):** 5개 데이터 소스의 이름, 종류, 데이터 내용, 규모까지 상세히 제공하여 AI가 추측이 아닌, 주어진 정보를 기반으로 정확한 해결책을 만들게 합니다. "데이터가 엉켰다"는 문제 상황까지 명시하여 문제 해결에 초점을 맞추게 합니다.
4.  **구조화된 요청 (Structured Request):** "스키마 설계", "ETL 전략", "API 설계", "기술 스택 제안"이라는 4개의 명확한 Task로 나누어 요청함으로써, AI가 답변해야 할 항목을 빠짐없이, 그리고 체계적으로 구성하도록 만듭니다.
5.  **실행 가능한 산출물 요구 (Actionable Outputs):** 단순히 "방법을 알려줘"가 아니라, `CREATE TABLE` SQL 구문, 의사코드(Pseudocode), JSON 예시 등 개발자가 바로 가져다 쓸 수 있는 구체적인 결과물을 요구합니다. 이는 아이디어를 실제 코드로 전환하는 데 드는 노력을 크게 줄여줍니다.
6.  **핵심 문제 명시:** 데이터 통합의 가장 어려운 부분인 **'개체 식별(Entity Resolution)'** 문제를 직접 언급하며 해결책을 요구함으로써, 가장 중요한 기술적 허들을 넘을 수 있는 방안을 얻어낼 수 있습니다.

이 프롬프트를 사용하시면, 데이터 통합이라는 복잡한 문제를 해결하고 원하시는 서비스를 성공적으로 구축하는 데 필요한 구체적인 청사진을 얻으실 수 있을 겁니다.
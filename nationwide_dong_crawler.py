#!/usr/bin/env python3
"""
ì „êµ­ ë™ë‹¨ìœ„ ì™„ì „ í¬ë¡¤ë§ ì‹œìŠ¤í…œ
- ì „êµ­ ëª¨ë“  ì‹œ/êµ¬/ë™ ì„¸ë¶„í™” í¬ë¡¤ë§
- ëª¨ë“  ê±°ë˜ íƒ€ì… í¬í•¨ (ë§¤ë§¤+ì „ì„¸+ì›”ì„¸)
- IP ì°¨ë‹¨ ë°©ì§€ ì‹œìŠ¤í…œ
- ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ìµœì í™”
- ìë™ ì¬ì‹œë„ ë° ë³µêµ¬ ì‹œìŠ¤í…œ
"""

import asyncio
import aiohttp
import sqlite3
import json
import time
import random
from datetime import datetime
from typing import List, Dict, Optional, Tuple
from urllib.parse import urlencode
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('nationwide_dong_crawling.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class NationwideDongCrawler:
    def __init__(self, db_path="real_estate_crawling.db"):
        self.db_path = db_path
        self.base_url = "https://new.land.naver.com/api/complexes/single-markers/2.0"
        self.session = None
        self.init_database()
        
    def init_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” - ìƒì„¸í•œ ìŠ¤í‚¤ë§ˆ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œí•˜ê³  ìƒˆë¡œìš´ êµ¬ì¡°ë¡œ ìƒì„±
        cursor.execute('DROP TABLE IF EXISTS apartment_complexes')
        cursor.execute('DROP TABLE IF EXISTS crawling_progress')
        
        # ìƒˆë¡œìš´ ìƒì„¸ ì•„íŒŒíŠ¸ í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE apartment_complexes (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                complex_id TEXT UNIQUE NOT NULL,
                complex_name TEXT NOT NULL,
                city TEXT NOT NULL,
                gu TEXT NOT NULL,
                dong TEXT NOT NULL,
                address_road TEXT,
                address_jibun TEXT,
                latitude REAL,
                longitude REAL,
                total_units INTEGER,
                construction_year INTEGER,
                
                -- ë§¤ë§¤ ê°€ê²© (ë§Œì›)
                deal_min_price INTEGER,
                deal_max_price INTEGER,
                deal_count INTEGER DEFAULT 0,
                
                -- ì „ì„¸ ê°€ê²© (ë§Œì›)
                lease_min_price INTEGER,
                lease_max_price INTEGER,
                lease_count INTEGER DEFAULT 0,
                
                -- ì›”ì„¸ ê°€ê²© (ë§Œì›)
                rent_min_price INTEGER,
                rent_max_price INTEGER,
                rent_min_deposit INTEGER,
                rent_max_deposit INTEGER,
                rent_count INTEGER DEFAULT 0,
                
                -- ë©´ì  ì •ë³´ (ã¡)
                min_area REAL,
                max_area REAL,
                representative_area REAL,
                
                -- ë©”íƒ€ ì •ë³´
                real_estate_type TEXT,
                trade_types TEXT,  -- ë§¤ë§¤,ì „ì„¸,ì›”ì„¸ ì¤‘ ì–´ë–¤ ê±°ë˜ê°€ ìˆëŠ”ì§€
                source_url TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                
                -- ì›ë³¸ ë°ì´í„°
                raw_data TEXT
            )
        ''')
        
        # í¬ë¡¤ë§ ì§„í–‰ ìƒí™© í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE crawling_progress (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                city TEXT,
                gu TEXT,  
                dong TEXT,
                trade_type TEXT,
                status TEXT,  -- pending, processing, completed, failed, skipped
                apartment_count INTEGER DEFAULT 0,
                crawl_start_time TIMESTAMP,
                crawl_end_time TIMESTAMP,
                error_message TEXT,
                retry_count INTEGER DEFAULT 0
            )
        ''')
        
        # ì¸ë±ìŠ¤ ìƒì„±
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_complex_id ON apartment_complexes(complex_id)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_location ON apartment_complexes(city, gu, dong)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_progress ON crawling_progress(city, gu, dong, trade_type)')
        
        conn.commit()
        conn.close()
        logger.info("âœ… ìƒˆë¡œìš´ ìƒì„¸ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡° ì´ˆê¸°í™” ì™„ë£Œ")

    async def init_session(self):
        """HTTP ì„¸ì…˜ ì´ˆê¸°í™”"""
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8',
            'Referer': 'https://new.land.naver.com/',
            'Origin': 'https://new.land.naver.com',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Sec-Fetch-Dest': 'empty',
            'Sec-Fetch-Mode': 'cors',
            'Sec-Fetch-Site': 'same-origin',
            'Cache-Control': 'no-cache',
            'Pragma': 'no-cache'
        }
        
        timeout = aiohttp.ClientTimeout(total=60)
        self.session = aiohttp.ClientSession(headers=headers, timeout=timeout)
        
    async def close_session(self):
        """HTTP ì„¸ì…˜ ì¢…ë£Œ"""
        if self.session:
            await self.session.close()

    def get_nationwide_regions(self) -> Dict[str, Dict[str, List[Tuple[str, str]]]]:
        """ì „êµ­ ì‹œ/êµ¬/ë™ ì¢Œí‘œ ë°ì´í„°"""
        return {
            "ì„œìš¸": {
                "ê°•ë‚¨êµ¬": [
                    ("ì‹ ì‚¬ë™", "1168010500"),
                    ("ë…¼í˜„ë™", "1168010500"),
                    ("ì••êµ¬ì •ë™", "1168010500"),
                    ("ì²­ë‹´ë™", "1168010500"),
                    ("ì‚¼ì„±ë™", "1168010500"),
                    ("ëŒ€ì¹˜ë™", "1168010500"),
                    ("ì—­ì‚¼ë™", "1168010500"),
                    ("ë„ê³¡ë™", "1168010500"),
                    ("ê°œí¬ë™", "1168010500"),
                    ("ì„¸ê³¡ë™", "1168010500"),
                    ("ìê³¡ë™", "1168010500"),
                    ("ìœ¨í˜„ë™", "1168010500"),
                    ("ì¼ì›ë™", "1168010500"),
                    ("ìˆ˜ì„œë™", "1168010500")
                ],
                "ì„œì´ˆêµ¬": [
                    ("ì„œì´ˆë™", "1168011900"),
                    ("ì ì›ë™", "1168011900"),
                    ("ë°˜í¬ë™", "1168011900"),
                    ("ë°©ë°°ë™", "1168011900"),
                    ("ì–‘ì¬ë™", "1168011900"),
                    ("ë‚´ê³¡ë™", "1168011900"),
                    ("ì—¼ê³¡ë™", "1168011900"),
                    ("ì›ì§€ë™", "1168011900"),
                    ("ìš°ë©´ë™", "1168011900"),
                    ("ì‹ ë°˜í¬ë™", "1168011900"),
                    ("ê°œí¬ë™", "1168011900"),
                    ("ë„ê³¡ë™", "1168011900"),
                    ("ëŒ€ì¹˜ë™", "1168011900"),
                    ("ì—­ì‚¼ë™", "1168011900"),
                    ("ë…¼í˜„ë™", "1168011900"),
                    ("ë°˜í¬ë³¸ë™", "1168011900"),
                    ("ì„œì´ˆì¤‘ì•™ë™", "1168011900"),
                    ("ê°€ë½ë™", "1168011900")
                ],
                "ì†¡íŒŒêµ¬": [
                    ("ê°€ë½ë™", "1168012200"),
                    ("ê±°ì—¬ë™", "1168012200"),
                    ("ë§ˆì²œë™", "1168012200"),
                    ("ë¬¸ì •ë™", "1168012200"),
                    ("ë°©ì´ë™", "1168012200"),
                    ("ì‚¼ì „ë™", "1168012200"),
                    ("ì„ì´Œë™", "1168012200"),
                    ("ì†¡íŒŒë™", "1168012200"),
                    ("ì‹ ì²œë™", "1168012200"),
                    ("ì˜¤ê¸ˆë™", "1168012200"),
                    ("ì˜¤ë¥œë™", "1168012200"),
                    ("ì ì‹¤ë™", "1168012200"),
                    ("ì¥ì§€ë™", "1168012200"),
                    ("í’ë‚©ë™", "1168012200")
                ],
                "ê°•ë™êµ¬": [
                    ("ê°•ì¼ë™", "1168010600"),
                    ("ê³ ë•ë™", "1168010600"),
                    ("ê¸¸ë™", "1168010600"),
                    ("ë‘”ì´Œë™", "1168010600"),
                    ("ëª…ì¼ë™", "1168010600"),
                    ("ìƒì¼ë™", "1168010600"),
                    ("ì„±ë‚´ë™", "1168010600"),
                    ("ì•”ì‚¬ë™", "1168010600"),
                    ("ì²œí˜¸ë™", "1168010600")
                ],
                "ë§ˆí¬êµ¬": [
                    ("ê³µë•ë™", "1168011700"),
                    ("êµ¬ìˆ˜ë™", "1168011700"),
                    ("ë…¸ê³ ì‚°ë™", "1168011700"),
                    ("ëŒ€í¥ë™", "1168011700"),
                    ("ë„í™”ë™", "1168011700"),
                    ("ë™êµë™", "1168011700"),
                    ("ë§ˆí¬ë™", "1168011700"),
                    ("ë§ì›ë™", "1168011700"),
                    ("ìƒì•”ë™", "1168011700"),
                    ("ìƒìˆ˜ë™", "1168011700"),
                    ("ì„œêµë™", "1168011700"),
                    ("ì„±ì‚°ë™", "1168011700"),
                    ("ì‹ ê³µë•ë™", "1168011700"),
                    ("ì•„í˜„ë™", "1168011700"),
                    ("ì—°ë‚¨ë™", "1168011700"),
                    ("ì—¼ë¦¬ë™", "1168011700"),
                    ("ìš©ê°•ë™", "1168011700"),
                    ("í† ì •ë™", "1168011700"),
                    ("í•˜ì¤‘ë™", "1168011700"),
                    ("í•©ì •ë™", "1168011700"),
                    ("í˜„ì„ë™", "1168011700")
                ]
            },
            "ë¶€ì‚°": {
                "í•´ìš´ëŒ€êµ¬": [
                    ("ìš°ë™", "2644010100"),
                    ("ì¤‘ë™", "2644010100"),
                    ("ì¢Œë™", "2644010100"),
                    ("ì†¡ì •ë™", "2644010100"),
                    ("ë°˜ì—¬ë™", "2644010100"),
                    ("ë°˜ì†¡ë™", "2644010100"),
                    ("ì¬ì†¡ë™", "2644010100")
                ],
                "ìˆ˜ì˜êµ¬": [
                    ("ë‚¨ì²œë™", "2644010200"),
                    ("ë¯¼ë½ë™", "2644010200"),
                    ("ìˆ˜ì˜ë™", "2644010200"),
                    ("ë§ë¯¸ë™", "2644010200"),
                    ("ê´‘ì•ˆë™", "2644010200")
                ]
            },
            "ì¸ì²œ": {
                "ì—°ìˆ˜êµ¬": [
                    ("ì—°ìˆ˜ë™", "2811010400"),
                    ("ì„ í•™ë™", "2811010400"),
                    ("ì²­í•™ë™", "2811010400"),
                    ("ë™ì¶˜ë™", "2811010400"),
                    ("ì†¡ë„ë™", "2811010400"),
                    ("ì˜¥ë ¨ë™", "2811010400")
                ]
            }
        }

    def get_dong_coordinates(self, city: str, gu: str, dong: str) -> Tuple[float, float, float, float]:
        """ë™ë‹¨ìœ„ ìƒì„¸ ì¢Œí‘œ ê³„ì‚°"""
        # ê¸°ë³¸ ì¢Œí‘œ ë§µí•‘ (ì‹¤ì œë¡œëŠ” ë” ì •í™•í•œ ì¢Œí‘œ ì‚¬ìš©)
        base_coords = {
            # ì„œìš¸ ê°•ë‚¨êµ¬
            "ì„œìš¸_ê°•ë‚¨êµ¬_ì‹ ì‚¬ë™": (127.020, 127.030, 37.525, 37.515),
            "ì„œìš¸_ê°•ë‚¨êµ¬_ë…¼í˜„ë™": (127.025, 127.035, 37.515, 37.505),
            "ì„œìš¸_ê°•ë‚¨êµ¬_ì••êµ¬ì •ë™": (127.025, 127.035, 37.530, 37.520),
            "ì„œìš¸_ê°•ë‚¨êµ¬_ì²­ë‹´ë™": (127.040, 127.050, 37.525, 37.515),
            "ì„œìš¸_ê°•ë‚¨êµ¬_ì‚¼ì„±ë™": (127.050, 127.060, 37.515, 37.505),
            "ì„œìš¸_ê°•ë‚¨êµ¬_ëŒ€ì¹˜ë™": (127.055, 127.065, 37.505, 37.495),
            "ì„œìš¸_ê°•ë‚¨êµ¬_ì—­ì‚¼ë™": (127.030, 127.040, 37.505, 37.495),
            "ì„œìš¸_ê°•ë‚¨êµ¬_ë„ê³¡ë™": (127.040, 127.050, 37.495, 37.485),
            "ì„œìš¸_ê°•ë‚¨êµ¬_ê°œí¬ë™": (127.055, 127.065, 37.485, 37.475),
            
            # ì„œìš¸ ì„œì´ˆêµ¬ (ê¸°ì¡´ í…ŒìŠ¤íŠ¸ ë°ì´í„° í™œìš©)
            "ì„œìš¸_ì„œì´ˆêµ¬_ë°©ë°°ë™": (126.995, 127.015, 37.485, 37.475),
            "ì„œìš¸_ì„œì´ˆêµ¬_ì„œì´ˆë™": (127.015, 127.035, 37.495, 37.485),
            "ì„œìš¸_ì„œì´ˆêµ¬_ë°˜í¬ë™": (126.995, 127.015, 37.515, 37.505),
            "ì„œìš¸_ì„œì´ˆêµ¬_ì ì›ë™": (127.015, 127.035, 37.525, 37.515),
            
            # ê¸°ë³¸ê°’
            "default": (127.000, 127.020, 37.500, 37.480)
        }
        
        key = f"{city}_{gu}_{dong}"
        return base_coords.get(key, base_coords["default"])

    def get_trade_types(self) -> List[str]:
        """ê±°ë˜ íƒ€ì… ëª©ë¡"""
        return ["ë§¤ë§¤", "ì „ì„¸", "ì›”ì„¸"]

    def get_trade_type_code(self, trade_type: str) -> str:
        """ê±°ë˜ íƒ€ì… ì½”ë“œ ë³€í™˜"""
        codes = {
            "ë§¤ë§¤": "A1",
            "ì „ì„¸": "B1", 
            "ì›”ì„¸": "B2"
        }
        return codes.get(trade_type, "A1")

    async def crawl_dong_trade_type(self, city: str, gu: str, dong: str, region_code: str, trade_type: str) -> int:
        """íŠ¹ì • ë™ì˜ íŠ¹ì • ê±°ë˜íƒ€ì… í¬ë¡¤ë§"""
        coords = self.get_dong_coordinates(city, gu, dong)
        trade_code = self.get_trade_type_code(trade_type)
        
        # ì´ë¯¸ ì™„ë£Œëœ ê²½ìš° ìŠ¤í‚µ
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute("""
            SELECT status FROM crawling_progress 
            WHERE city = ? AND gu = ? AND dong = ? AND trade_type = ? AND status = 'completed'
        """, (city, gu, dong, trade_type))
        
        if cursor.fetchone():
            conn.close()
            logger.info(f"â­ï¸ {city} {gu} {dong} {trade_type}: ì´ë¯¸ ì™„ë£Œë¨")
            return 0
        conn.close()
        
        # ì§„í–‰ ìƒí™© ê¸°ë¡
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute("""
            INSERT OR REPLACE INTO crawling_progress 
            (city, gu, dong, trade_type, status, crawl_start_time, retry_count)
            VALUES (?, ?, ?, ?, ?, ?, 0)
        """, (city, gu, dong, trade_type, 'processing', datetime.now()))
        conn.commit()
        progress_id = cursor.lastrowid
        conn.close()
        
        try:
            # API íŒŒë¼ë¯¸í„° êµ¬ì„±
            left_lon, right_lon, top_lat, bottom_lat = coords
            
            params = {
                'cortarNo': region_code,
                'zoom': '17',  # ë§¤ìš° ë†’ì€ ì¤Œ ë ˆë²¨
                'priceType': 'RETAIL',
                'markerId': '',
                'markerType': '',
                'selectedComplexNo': '',
                'selectedComplexBuildingNo': '',
                'fakeComplexMarker': '',
                'realEstateType': 'APT:ABYG:JGC:PRE',
                'tradeType': trade_code,
                'tag': '::::::::',
                'rentPriceMin': '0',
                'rentPriceMax': '999999999',
                'priceMin': '0',
                'priceMax': '999999999',
                'areaMin': '0',
                'areaMax': '999999999',
                'oldBuildYears': '99',
                'recentlyBuildYears': '0',
                'minHouseHoldCount': '',
                'maxHouseHoldCount': '',
                'showArticle': 'false',
                'sameAddressGroup': 'false',
                'minMaintenanceCost': '',
                'maxMaintenanceCost': '',
                'directions': '',
                'leftLon': str(left_lon),
                'rightLon': str(right_lon),
                'topLat': str(top_lat),
                'bottomLat': str(bottom_lat),
                'isPresale': 'true'
            }
            
            url = f"{self.base_url}?{urlencode(params)}"
            logger.info(f"ğŸ” API í˜¸ì¶œ: {city} {gu} {dong} {trade_type}")
            
            # API í˜¸ì¶œ
            async with self.session.get(url) as response:
                if response.status == 200:
                    data = await response.json()
                    
                    if isinstance(data, list):
                        count = self.save_apartments(data, city, gu, dong, trade_type)
                        
                        # ì„±ê³µ ê¸°ë¡
                        conn = sqlite3.connect(self.db_path)
                        cursor = conn.cursor()
                        cursor.execute("""
                            UPDATE crawling_progress 
                            SET status = ?, apartment_count = ?, crawl_end_time = ?
                            WHERE id = ?
                        """, ('completed', count, datetime.now(), progress_id))
                        conn.commit()
                        conn.close()
                        
                        logger.info(f"âœ… {city} {gu} {dong} {trade_type}: {count}ê°œ ìˆ˜ì§‘")
                        return count
                    else:
                        logger.warning(f"âš ï¸ {city} {gu} {dong} {trade_type}: ì˜ˆìƒê³¼ ë‹¤ë¥¸ ì‘ë‹µ")
                        return 0
                else:
                    logger.warning(f"âš ï¸ {city} {gu} {dong} {trade_type}: HTTP {response.status}")
                    return 0
                    
        except Exception as e:
            # ì‹¤íŒ¨ ê¸°ë¡
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute("""
                UPDATE crawling_progress
                SET status = ?, error_message = ?, crawl_end_time = ?
                WHERE id = ?
            """, ('failed', str(e), datetime.now(), progress_id))
            conn.commit()
            conn.close()
            
            logger.error(f"âŒ {city} {gu} {dong} {trade_type}: {e}")
            return 0

    def save_apartments(self, apartments_data: List[Dict], city: str, gu: str, dong: str, trade_type: str) -> int:
        """ì•„íŒŒíŠ¸ ë°ì´í„° ì €ì¥ (ì¤‘ë³µ ì œê±° ë° ì—…ë°ì´íŠ¸)"""
        if not apartments_data:
            return 0
            
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        saved_count = 0
        
        for item in apartments_data:
            try:
                complex_id = str(item.get('markerId', ''))
                if not complex_id:
                    continue
                
                # ì¤‘ë³µ í™•ì¸
                cursor.execute("""
                    SELECT id, trade_types FROM apartment_complexes WHERE complex_id = ?
                """, (complex_id,))
                
                existing = cursor.fetchone()
                
                if existing:
                    # ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸
                    existing_id, existing_trade_types = existing
                    trade_types_list = existing_trade_types.split(',') if existing_trade_types else []
                    
                    if trade_type not in trade_types_list:
                        trade_types_list.append(trade_type)
                    
                    # ê±°ë˜ íƒ€ì…ë³„ ê°€ê²© ì •ë³´ ì—…ë°ì´íŠ¸
                    update_fields = ['trade_types = ?', 'updated_at = ?']
                    update_values = [','.join(trade_types_list), datetime.now()]
                    
                    if trade_type == "ë§¤ë§¤":
                        update_fields.extend(['deal_min_price = ?', 'deal_max_price = ?', 'deal_count = ?'])
                        update_values.extend([
                            item.get('minDealPrice'),
                            item.get('maxDealPrice'), 
                            item.get('dealCount', 0)
                        ])
                    elif trade_type == "ì „ì„¸":
                        update_fields.extend(['lease_min_price = ?', 'lease_max_price = ?', 'lease_count = ?'])
                        update_values.extend([
                            item.get('minLeasePrice'),
                            item.get('maxLeasePrice'),
                            item.get('leaseCount', 0)
                        ])
                    elif trade_type == "ì›”ì„¸":
                        update_fields.extend(['rent_min_price = ?', 'rent_max_price = ?', 'rent_count = ?'])
                        update_values.extend([
                            item.get('minRentPrice'),
                            item.get('maxRentPrice'),
                            item.get('rentCount', 0)
                        ])
                    
                    update_values.append(complex_id)
                    
                    cursor.execute(f"""
                        UPDATE apartment_complexes 
                        SET {', '.join(update_fields)}
                        WHERE complex_id = ?
                    """, update_values)
                    
                else:
                    # ìƒˆ ë°ì´í„° ì‚½ì…
                    deal_min = deal_max = deal_count = None
                    lease_min = lease_max = lease_count = None  
                    rent_min = rent_max = rent_count = None
                    
                    if trade_type == "ë§¤ë§¤":
                        deal_min = item.get('minDealPrice')
                        deal_max = item.get('maxDealPrice')
                        deal_count = item.get('dealCount', 0)
                    elif trade_type == "ì „ì„¸":
                        lease_min = item.get('minLeasePrice')
                        lease_max = item.get('maxLeasePrice')
                        lease_count = item.get('leaseCount', 0)
                    elif trade_type == "ì›”ì„¸":
                        rent_min = item.get('minRentPrice')
                        rent_max = item.get('maxRentPrice')
                        rent_count = item.get('rentCount', 0)
                    
                    cursor.execute("""
                        INSERT INTO apartment_complexes (
                            complex_id, complex_name, city, gu, dong,
                            address_road, address_jibun, latitude, longitude,
                            total_units, construction_year,
                            deal_min_price, deal_max_price, deal_count,
                            lease_min_price, lease_max_price, lease_count,
                            rent_min_price, rent_max_price, rent_count,
                            min_area, max_area, representative_area,
                            real_estate_type, trade_types, raw_data
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """, (
                        complex_id,
                        item.get('complexName'),
                        city,
                        gu, 
                        dong,
                        f"{city} {gu} {dong}",
                        f"{city} {gu} {dong}",
                        item.get('latitude'),
                        item.get('longitude'),
                        item.get('totalHouseholdCount'),
                        self.extract_construction_year(item.get('completionYearMonth')),
                        deal_min, deal_max, deal_count,
                        lease_min, lease_max, lease_count,
                        rent_min, rent_max, rent_count,
                        item.get('minArea'),
                        item.get('maxArea'),
                        item.get('representativeArea'),
                        item.get('realEstateTypeName'),
                        trade_type,
                        json.dumps(item, ensure_ascii=False)
                    ))
                
                saved_count += 1
                
            except Exception as e:
                logger.error(f"ë°ì´í„° ì €ì¥ ì˜¤ë¥˜: {e}")
                continue
        
        conn.commit()
        conn.close()
        
        return saved_count

    def extract_construction_year(self, year_month: str) -> Optional[int]:
        """ê±´ì¶•ë…„ì›”ì—ì„œ ë…„ë„ ì¶”ì¶œ"""
        if not year_month:
            return None
        try:
            if len(str(year_month)) >= 4:
                return int(str(year_month)[:4])
        except:
            pass
        return None

    async def crawl_nationwide(self):
        """ì „êµ­ ë™ë‹¨ìœ„ í¬ë¡¤ë§"""
        logger.info("ğŸš€ ì „êµ­ ë™ë‹¨ìœ„ í¬ë¡¤ë§ ì‹œì‘!")
        
        await self.init_session()
        
        try:
            regions = self.get_nationwide_regions()
            total_count = 0
            
            for city, gus in regions.items():
                logger.info(f"ğŸ™ï¸ {city} í¬ë¡¤ë§ ì‹œì‘")
                
                for gu, dongs in gus.items():
                    logger.info(f"ğŸ“ {city} {gu} í¬ë¡¤ë§ ì‹œì‘")
                    
                    for dong, region_code in dongs:
                        logger.info(f"ğŸ˜ï¸ {city} {gu} {dong} í¬ë¡¤ë§ ì‹œì‘")
                        
                        dong_count = 0
                        
                        for trade_type in self.get_trade_types():
                            count = await self.crawl_dong_trade_type(city, gu, dong, region_code, trade_type)
                            dong_count += count
                            
                            # ê±°ë˜ íƒ€ì… ê°„ ë”œë ˆì´
                            delay = random.uniform(8, 12)
                            logger.info(f"â³ ë‹¤ìŒ ê±°ë˜ íƒ€ì…ê¹Œì§€ {delay:.1f}ì´ˆ ëŒ€ê¸°...")
                            await asyncio.sleep(delay)
                        
                        total_count += dong_count
                        logger.info(f"ğŸ¯ {city} {gu} {dong} ì™„ë£Œ: {dong_count}ê°œ ì•„íŒŒíŠ¸")
                        
                        # ë™ ê°„ ë”œë ˆì´
                        delay = random.uniform(15, 25)
                        logger.info(f"â³ ë‹¤ìŒ ë™ê¹Œì§€ {delay:.1f}ì´ˆ ëŒ€ê¸°...")
                        await asyncio.sleep(delay)
                    
                    logger.info(f"âœ… {city} {gu} ì™„ë£Œ")
                    
                logger.info(f"ğŸ‰ {city} ì™„ë£Œ!")
            
            logger.info(f"ğŸ† ì „êµ­ í¬ë¡¤ë§ ì™„ë£Œ! ì´ {total_count}ê°œ ì•„íŒŒíŠ¸ ìˆ˜ì§‘")
            
        finally:
            await self.close_session()

    def generate_progress_report(self):
        """ì§„í–‰ ìƒí™© ë¦¬í¬íŠ¸"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ì „ì²´ í†µê³„
        cursor.execute("SELECT COUNT(*) FROM apartment_complexes")
        total_apartments = cursor.fetchone()[0]
        
        # ì§€ì—­ë³„ í†µê³„
        cursor.execute("""
            SELECT city, gu, COUNT(*) as count
            FROM apartment_complexes 
            GROUP BY city, gu 
            ORDER BY city, gu
        """)
        region_stats = cursor.fetchall()
        
        # ê±°ë˜ íƒ€ì…ë³„ í†µê³„
        cursor.execute("""
            SELECT 
                COUNT(CASE WHEN deal_min_price IS NOT NULL THEN 1 END) as deal_count,
                COUNT(CASE WHEN lease_min_price IS NOT NULL THEN 1 END) as lease_count,
                COUNT(CASE WHEN rent_min_price IS NOT NULL THEN 1 END) as rent_count
            FROM apartment_complexes
        """)
        trade_stats = cursor.fetchone()
        
        # ì§„í–‰ ìƒí™©
        cursor.execute("""
            SELECT status, COUNT(*) 
            FROM crawling_progress 
            GROUP BY status
        """)
        progress_stats = cursor.fetchall()
        
        conn.close()
        
        print("\n" + "="*60)
        print("ğŸ“Š ì „êµ­ ë™ë‹¨ìœ„ í¬ë¡¤ë§ ì§„í–‰ ë¦¬í¬íŠ¸")
        print("="*60)
        print(f"ğŸ¢ ì´ ì•„íŒŒíŠ¸ ë‹¨ì§€: {total_apartments:,}ê°œ")
        
        print("\nğŸ—ºï¸ ì§€ì—­ë³„ í˜„í™©:")
        for city, gu, count in region_stats:
            print(f"  {city} {gu}: {count:,}ê°œ")
        
        print("\nğŸ’° ê±°ë˜ íƒ€ì…ë³„ í˜„í™©:")
        if trade_stats:
            print(f"  ë§¤ë§¤: {trade_stats[0]:,}ê°œ")
            print(f"  ì „ì„¸: {trade_stats[1]:,}ê°œ")
            print(f"  ì›”ì„¸: {trade_stats[2]:,}ê°œ")
        
        print("\nâš™ï¸ í¬ë¡¤ë§ ì§„í–‰ ìƒí™©:")
        total_tasks = sum(count for status, count in progress_stats)
        for status, count in progress_stats:
            percentage = (count / total_tasks * 100) if total_tasks > 0 else 0
            print(f"  {status}: {count:,}ê±´ ({percentage:.1f}%)")

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ì „êµ­ ë™ë‹¨ìœ„ í¬ë¡¤ë§ ì‹œì‘!")
    print("ğŸ“‹ í¬ë¡¤ë§ ì¡°ê±´:")
    print("  - ëŒ€ìƒ: ì „êµ­ ì£¼ìš” ë„ì‹œ ë™ë‹¨ìœ„")
    print("  - ê±°ë˜íƒ€ì…: ë§¤ë§¤ + ì „ì„¸ + ì›”ì„¸ (ì „ì²´)")
    print("  - ì•„íŒŒíŠ¸íƒ€ì…: ì•„íŒŒíŠ¸ + ë¶„ì–‘ê¶Œ + ì£¼íƒ (ì „ì²´)")
    print("  - ëª¨ë“  ì¡°ê±´: ë¬´ì œí•œ")
    print("  - IP ì°¨ë‹¨ ë°©ì§€: 8-25ì´ˆ ëœë¤ ë”œë ˆì´")
    print("  - DB: ìƒˆë¡œìš´ ìƒì„¸ êµ¬ì¡°")
    
    crawler = NationwideDongCrawler()
    
    start_time = time.time()
    await crawler.crawl_nationwide()
    end_time = time.time()
    
    crawler.generate_progress_report()
    
    print(f"\nâ±ï¸ ì´ ì†Œìš” ì‹œê°„: {(end_time - start_time)/3600:.1f}ì‹œê°„")
    print("ğŸ“ ê²°ê³¼ ì €ì¥: real_estate_crawling.db (ìƒˆë¡œìš´ ìƒì„¸ êµ¬ì¡°)")

if __name__ == "__main__":
    asyncio.run(main())
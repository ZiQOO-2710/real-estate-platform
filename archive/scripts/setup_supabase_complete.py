#!/usr/bin/env python3
"""
Supabase ì™„ì „ ìë™ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸
- í…Œì´ë¸” ìƒì„±
- ë°ì´í„° ì—…ë¡œë“œ  
- í”„ë¡ íŠ¸ì—”ë“œ í™˜ê²½ë³€ìˆ˜ ì„¤ì •
"""

import os
import sys
import json
import asyncio
import logging
from pathlib import Path
from supabase import create_client, Client
from datetime import datetime

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

class SupabaseCompleteSetup:
    def __init__(self, supabase_url: str, supabase_key: str):
        """Supabase ì™„ì „ ì„¤ì • í´ë˜ìŠ¤"""
        try:
            # ê¸°ë³¸ ì˜µì…˜ë§Œìœ¼ë¡œ í´ë¼ì´ì–¸íŠ¸ ìƒì„± (proxy íŒŒë¼ë¯¸í„° ì œê±°)
            self.supabase: Client = create_client(supabase_url, supabase_key)
            self.url = supabase_url
            self.key = supabase_key
            logger.info("âœ… Supabase í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì„±ê³µ")
        except Exception as e:
            logger.error(f"âŒ Supabase ì—°ê²° ì‹¤íŒ¨: {e}")
            # ì—°ê²° ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
            self.supabase = None
            self.url = supabase_url
            self.key = supabase_key
    
    def create_tables(self) -> bool:
        """í…Œì´ë¸” ìƒì„±"""
        logger.info("ğŸ—ï¸ ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„± ì¤‘...")
        
        # ì•„íŒŒíŠ¸ ë‹¨ì§€ í…Œì´ë¸”
        apartment_complexes_sql = """
        CREATE TABLE IF NOT EXISTS apartment_complexes (
            id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
            complex_id VARCHAR(50) UNIQUE NOT NULL,
            complex_name VARCHAR(200) NOT NULL,
            address_road TEXT,
            address_jibun TEXT,
            dong VARCHAR(100),
            gu VARCHAR(100), 
            city VARCHAR(100),
            latitude DECIMAL(10, 8),
            longitude DECIMAL(11, 8),
            total_units INTEGER,
            construction_year INTEGER,
            floors INTEGER,
            parking_ratio INTEGER,
            last_transaction_price INTEGER,
            last_transaction_date DATE,
            current_asking_price INTEGER,
            price_per_pyeong INTEGER,
            source_url TEXT,
            created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
            updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
        );
        """
        
        # í˜„ì¬ ë§¤ë¬¼ í…Œì´ë¸”
        current_listings_sql = """
        CREATE TABLE IF NOT EXISTS current_listings (
            id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
            complex_id VARCHAR(50) NOT NULL,
            deal_type VARCHAR(20) NOT NULL,
            price_amount INTEGER,
            deposit_amount INTEGER,
            monthly_rent INTEGER,
            area_sqm DECIMAL(7, 2),
            area_pyeong DECIMAL(7, 2),
            floor_info VARCHAR(50),
            direction VARCHAR(20),
            description TEXT,
            listing_date DATE,
            created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
            FOREIGN KEY (complex_id) REFERENCES apartment_complexes(complex_id)
        );
        """
        
        # ì‹¤ê±°ë˜ê°€ í…Œì´ë¸”  
        transaction_history_sql = """
        CREATE TABLE IF NOT EXISTS transaction_history (
            id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
            complex_id VARCHAR(50) NOT NULL,
            transaction_type VARCHAR(20) NOT NULL,
            price_amount INTEGER NOT NULL,
            area_sqm DECIMAL(7, 2),
            area_pyeong DECIMAL(7, 2),
            floor_info VARCHAR(50),
            transaction_date DATE,
            created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
            FOREIGN KEY (complex_id) REFERENCES apartment_complexes(complex_id)
        );
        """
        
        # ì¸ë±ìŠ¤ ìƒì„±
        indexes_sql = """
        CREATE INDEX IF NOT EXISTS idx_apartment_complexes_location 
        ON apartment_complexes(latitude, longitude);
        
        CREATE INDEX IF NOT EXISTS idx_apartment_complexes_region 
        ON apartment_complexes(city, gu, dong);
        
        CREATE INDEX IF NOT EXISTS idx_current_listings_complex 
        ON current_listings(complex_id);
        
        CREATE INDEX IF NOT EXISTS idx_transaction_history_complex 
        ON transaction_history(complex_id);
        
        CREATE INDEX IF NOT EXISTS idx_transaction_history_date 
        ON transaction_history(transaction_date);
        """
        
        try:
            # SQL ì‹¤í–‰
            tables = [apartment_complexes_sql, current_listings_sql, transaction_history_sql, indexes_sql]
            for i, sql in enumerate(tables, 1):
                self.supabase.postgrest.rpc('exec_sql', {'query': sql}).execute()
                logger.info(f"âœ… ë‹¨ê³„ {i}/4 ì™„ë£Œ")
                
            logger.info("ğŸ‰ ëª¨ë“  í…Œì´ë¸” ìƒì„± ì™„ë£Œ!")
            return True
            
        except Exception as e:
            logger.error(f"âŒ í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")
            logger.info("ğŸ’¡ Supabase ëŒ€ì‹œë³´ë“œì—ì„œ ìˆ˜ë™ìœ¼ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”.")
            return False
    
    def load_crawling_data(self) -> list:
        """í¬ë¡¤ë§ ë°ì´í„° ë¡œë“œ"""
        logger.info("ğŸ“‚ í¬ë¡¤ë§ ë°ì´í„° íŒŒì¼ ê²€ìƒ‰ ì¤‘...")
        
        data_dir = Path("modules/naver-crawler/data/output")
        if not data_dir.exists():
            data_dir = Path("data/output")
        
        json_files = list(data_dir.glob("*comprehensive*.json"))
        
        if not json_files:
            logger.warning("âš ï¸ í¬ë¡¤ë§ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        latest_file = max(json_files, key=os.path.getctime)
        logger.info(f"ğŸ“„ ë°ì´í„° íŒŒì¼: {latest_file}")
        
        try:
            with open(latest_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            logger.info(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(data)} ê°œ í•­ëª©")
            return data
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []
    
    def parse_price(self, price_str: str) -> int:
        """ê°€ê²© íŒŒì‹± (ë§Œì› ë‹¨ìœ„)"""
        if not price_str or price_str == '-':
            return None
            
        # ìˆ«ìë§Œ ì¶”ì¶œ
        import re
        numbers = re.findall(r'[\d,]+', str(price_str))
        if not numbers:
            return None
            
        try:
            # ì‰¼í‘œ ì œê±° í›„ ìˆ«ì ë³€í™˜
            num_str = numbers[0].replace(',', '')
            amount = int(num_str)
            
            # ë‹¨ìœ„ í™•ì¸
            price_str = str(price_str)
            if 'ì–µ' in price_str:
                if 'ì²œ' in price_str or 'ë§Œ' in price_str:
                    # "14ì–µ 5,000" í˜•íƒœ
                    if len(numbers) > 1:
                        decimal = int(numbers[1].replace(',', ''))
                        amount = amount * 10000 + decimal
                    else:
                        amount = amount * 10000
                else:
                    # "14ì–µ" í˜•íƒœ
                    amount = amount * 10000
            elif 'ë§Œ' in price_str:
                # "5,000ë§Œ" í˜•íƒœ
                pass  # ì´ë¯¸ ë§Œì› ë‹¨ìœ„
            elif 'ì²œ' in price_str:
                # "3ì²œë§Œì›" í˜•íƒœ  
                amount = amount * 1000
                
            return amount
            
        except Exception:
            return None
    
    def parse_area(self, area_str: str) -> tuple:
        """ë©´ì  íŒŒì‹± (ã¡, í‰)"""
        if not area_str or area_str == '-':
            return None, None
            
        try:
            import re
            
            # ìˆ«ì ì¶”ì¶œ
            numbers = re.findall(r'[\d.]+', str(area_str))
            if not numbers:
                return None, None
                
            area_num = float(numbers[0])
            
            if 'ã¡' in str(area_str):
                # ã¡ -> í‰ ë³€í™˜
                sqm = area_num
                pyeong = sqm / 3.3058
            elif 'í‰' in str(area_str):
                # í‰ -> ã¡ ë³€í™˜  
                pyeong = area_num
                sqm = pyeong * 3.3058
            else:
                # ë‹¨ìœ„ ì—†ìœ¼ë©´ ã¡ë¡œ ê°€ì •
                sqm = area_num
                pyeong = sqm / 3.3058
                
            return round(sqm, 2), round(pyeong, 2)
            
        except Exception:
            return None, None
    
    def upload_apartment_data(self, crawling_data: list) -> bool:
        """ì•„íŒŒíŠ¸ ë°ì´í„° ì—…ë¡œë“œ"""
        logger.info("ğŸ“¤ ì•„íŒŒíŠ¸ ë°ì´í„° ì—…ë¡œë“œ ì¤‘...")
        
        if not crawling_data:
            logger.warning("âš ï¸ ì—…ë¡œë“œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
            
        uploaded_count = 0
        
        for item in crawling_data:
            try:
                # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
                complex_data = {
                    'complex_id': str(item.get('complex_id', '')),
                    'complex_name': item.get('complex_name', ''),
                    'address_road': item.get('address', ''),
                    'address_jibun': item.get('address_detail', ''),
                    'source_url': item.get('source_url', ''),
                }
                
                # ì£¼ì†Œ íŒŒì‹±
                address = item.get('address', '')
                if address:
                    parts = address.split()
                    if len(parts) >= 3:
                        complex_data['city'] = parts[0]
                        complex_data['gu'] = parts[1] 
                        complex_data['dong'] = parts[2]
                
                # ìƒì„¸ ì •ë³´
                details = item.get('basic_info', {})
                if details:
                    # ì„¸ëŒ€ìˆ˜
                    households = details.get('ì´ ì„¸ëŒ€ìˆ˜', '')
                    if households and households != '-':
                        import re
                        nums = re.findall(r'\d+', str(households))
                        if nums:
                            complex_data['total_units'] = int(nums[0])
                    
                    # ê±´ì¶•ë…„ë„
                    year = details.get('ì¤€ê³µ', '')
                    if year and year != '-':
                        import re
                        nums = re.findall(r'\d{4}', str(year))
                        if nums:
                            complex_data['construction_year'] = int(nums[0])
                
                # ê°€ê²© ì •ë³´ (ì²« ë²ˆì§¸ ë§¤ë¬¼ì—ì„œ)
                listings = item.get('current_listings', [])
                if listings:
                    first_listing = listings[0]
                    price = self.parse_price(first_listing.get('price', ''))
                    if price:
                        complex_data['last_transaction_price'] = price
                
                # ì‹¤ê±°ë˜ê°€ (í‰ê· )
                transactions = item.get('transaction_history', [])
                if transactions:
                    prices = []
                    for trans in transactions:
                        price = self.parse_price(trans.get('price', ''))
                        if price:
                            prices.append(price)
                    
                    if prices:
                        complex_data['last_transaction_price'] = int(sum(prices) / len(prices))
                
                # ì¢Œí‘œ ì¶”ê°€ (ì„œìš¸ ì¤‘ì‹¬ìœ¼ë¡œ ì„ì‹œ ì„¤ì •)
                import random
                complex_data['latitude'] = 37.5665 + random.uniform(-0.1, 0.1)
                complex_data['longitude'] = 126.9780 + random.uniform(-0.1, 0.1)
                
                # DBì— ì‚½ì… (upsert)
                result = self.supabase.table('apartment_complexes')\
                    .upsert(complex_data, on_conflict='complex_id')\
                    .execute()
                
                uploaded_count += 1
                
                if uploaded_count % 10 == 0:
                    logger.info(f"ğŸ“¤ ì§„í–‰ë¥ : {uploaded_count}/{len(crawling_data)}")
                    
            except Exception as e:
                logger.warning(f"âš ï¸ ë°ì´í„° ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
                continue
        
        logger.info(f"ğŸ‰ ë°ì´í„° ì—…ë¡œë“œ ì™„ë£Œ: {uploaded_count}ê°œ")
        return uploaded_count > 0
    
    def update_frontend_env(self) -> bool:
        """í”„ë¡ íŠ¸ì—”ë“œ í™˜ê²½ë³€ìˆ˜ ì—…ë°ì´íŠ¸"""
        logger.info("âš™ï¸ í”„ë¡ íŠ¸ì—”ë“œ í™˜ê²½ë³€ìˆ˜ ì—…ë°ì´íŠ¸ ì¤‘...")
        
        env_file = Path("frontend/.env")
        
        try:
            # ê¸°ì¡´ .env íŒŒì¼ ì½ê¸°
            if env_file.exists():
                with open(env_file, 'r', encoding='utf-8') as f:
                    content = f.read()
            else:
                content = ""
            
            # Supabase ì„¤ì • ì—…ë°ì´íŠ¸
            lines = content.split('\n')
            updated_lines = []
            
            supabase_url_updated = False
            supabase_key_updated = False
            
            for line in lines:
                if line.startswith('REACT_APP_SUPABASE_URL='):
                    updated_lines.append(f'REACT_APP_SUPABASE_URL={self.url}')
                    supabase_url_updated = True
                elif line.startswith('REACT_APP_SUPABASE_ANON_KEY='):
                    updated_lines.append(f'REACT_APP_SUPABASE_ANON_KEY={self.key}')
                    supabase_key_updated = True
                else:
                    updated_lines.append(line)
            
            # ì—†ìœ¼ë©´ ì¶”ê°€
            if not supabase_url_updated:
                updated_lines.append(f'REACT_APP_SUPABASE_URL={self.url}')
            if not supabase_key_updated:
                updated_lines.append(f'REACT_APP_SUPABASE_ANON_KEY={self.key}')
            
            # íŒŒì¼ ì €ì¥
            with open(env_file, 'w', encoding='utf-8') as f:
                f.write('\n'.join(updated_lines))
            
            logger.info("âœ… í™˜ê²½ë³€ìˆ˜ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ í™˜ê²½ë³€ìˆ˜ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def test_final_setup(self) -> bool:
        """ìµœì¢… ì„¤ì • í…ŒìŠ¤íŠ¸"""
        logger.info("ğŸ§ª ìµœì¢… ì„¤ì • í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        try:
            # í…Œì´ë¸” ì¡´ì¬ í™•ì¸
            result = self.supabase.table('apartment_complexes').select('*').limit(1).execute()
            
            if result.data:
                logger.info(f"âœ… ë°ì´í„° í™•ì¸: {len(result.data)}ê°œ ë ˆì½”ë“œ")
                
                # ì²« ë²ˆì§¸ ë ˆì½”ë“œ ì •ë³´ ì¶œë ¥
                first_record = result.data[0]
                logger.info(f"ğŸ“ ì˜ˆì‹œ ë°ì´í„°: {first_record.get('complex_name', 'N/A')}")
                
                return True
            else:
                logger.warning("âš ï¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ì„¤ì • í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ Supabase ì™„ì „ ìë™ ì„¤ì •ì„ ì‹œì‘í•©ë‹ˆë‹¤!")
    print("=" * 50)
    
    # í™˜ê²½ë³€ìˆ˜ í™•ì¸
    supabase_url = input("Supabase Project URLì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    supabase_key = input("Supabase anon keyë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    
    if not supabase_url or not supabase_key:
        print("âŒ Supabase URLê³¼ Keyê°€ í•„ìš”í•©ë‹ˆë‹¤!")
        return
    
    # ì„¤ì • ì‹¤í–‰
    setup = SupabaseCompleteSetup(supabase_url, supabase_key)
    
    print("\nğŸ“‹ ì‹¤í–‰ ë‹¨ê³„:")
    print("1. ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„±")
    print("2. í¬ë¡¤ë§ ë°ì´í„° ë¡œë“œ")  
    print("3. ë°ì´í„° ì—…ë¡œë“œ")
    print("4. í”„ë¡ íŠ¸ì—”ë“œ í™˜ê²½ë³€ìˆ˜ ì„¤ì •")
    print("5. ìµœì¢… í…ŒìŠ¤íŠ¸")
    
    # 1. í…Œì´ë¸” ìƒì„±
    print("\nğŸ—ï¸ 1. í…Œì´ë¸” ìƒì„± ì¤‘...")
    if not setup.create_tables():
        print("âŒ í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨")
        return
    
    # 2. ë°ì´í„° ë¡œë“œ  
    print("\nğŸ“‚ 2. í¬ë¡¤ë§ ë°ì´í„° ë¡œë“œ ì¤‘...")
    crawling_data = setup.load_crawling_data()
    if not crawling_data:
        print("âš ï¸ í¬ë¡¤ë§ ë°ì´í„°ê°€ ì—†ì–´ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
        # ìƒ˜í”Œ ë°ì´í„° ìƒì„± ë¡œì§ ì¶”ê°€ ê°€ëŠ¥
    
    # 3. ë°ì´í„° ì—…ë¡œë“œ
    print("\nğŸ“¤ 3. ë°ì´í„° ì—…ë¡œë“œ ì¤‘...")
    if not setup.upload_apartment_data(crawling_data):
        print("âŒ ë°ì´í„° ì—…ë¡œë“œ ì‹¤íŒ¨")
        return
    
    # 4. í™˜ê²½ë³€ìˆ˜ ì„¤ì •
    print("\nâš™ï¸ 4. í”„ë¡ íŠ¸ì—”ë“œ í™˜ê²½ë³€ìˆ˜ ì„¤ì • ì¤‘...")
    setup.update_frontend_env()
    
    # 5. ìµœì¢… í…ŒìŠ¤íŠ¸
    print("\nğŸ§ª 5. ìµœì¢… í…ŒìŠ¤íŠ¸ ì¤‘...")
    if setup.test_final_setup():
        print("\nğŸ‰ ëª¨ë“  ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("\nğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:")
        print("1. í”„ë¡ íŠ¸ì—”ë“œ ì¬ì‹œì‘: npm start")
        print("2. ë¸Œë¼ìš°ì €ì—ì„œ ì§€ë„ í™•ì¸: http://localhost:3000/map")
        print("3. DB ë°ì´í„°ê°€ ì§€ë„ì— í‘œì‹œë˜ëŠ”ì§€ í™•ì¸")
    else:
        print("\nâš ï¸ ì¼ë¶€ ì„¤ì •ì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print("Supabase ëŒ€ì‹œë³´ë“œì—ì„œ í™•ì¸í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main()
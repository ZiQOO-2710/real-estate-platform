#!/usr/bin/env python3
"""
ì„œìš¸ ì§€ì—­ ì•„íŒŒíŠ¸ í¬ë¡¤ë§ í›„ DB ì €ì¥
"""

import asyncio
import sys
import os
sys.path.append('/home/ksj27/projects/real-estate-platform/modules/naver-crawler')

from core.crawler import NaverRealEstateCrawler
from setup_supabase_complete import SupabaseCompleteSetup

class SeoulCrawlerWithDB:
    def __init__(self):
        self.setup = SupabaseCompleteSetup(
            'https://heatmxifhwxppprdzaqf.supabase.co',
            'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImhlYXRteGlmaHd4cHBwcmR6YXFmIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTI0NzQ3OTMsImV4cCI6MjA2ODA1MDc5M30.NRcHrm5Y7ooHGkCxrD2QdStea-KnyVBIUCTpFB9x89o'
        )
    
    def convert_apartment_to_db_format(self, apt, region_name):
        """ì•„íŒŒíŠ¸ ë°ì´í„°ë¥¼ DB í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        
        # í‰ê·  ê°€ê²© ê³„ì‚°
        avg_price = None
        if apt.min_deal_price and apt.max_deal_price:
            avg_price = (apt.min_deal_price + apt.max_deal_price) // 2
        elif apt.min_deal_price:
            avg_price = apt.min_deal_price
        elif apt.max_deal_price:
            avg_price = apt.max_deal_price
        
        # ê±´ì¶•ë…„ë„ ì¶”ì¶œ (201305 -> 2013)
        construction_year = None
        if apt.completion_year_month:
            try:
                year_str = str(apt.completion_year_month)[:4]
                construction_year = int(year_str)
            except:
                pass
        
        # ì§€ì—­ ì •ë³´ íŒŒì‹±
        city, gu = region_name.split('_') if '_' in region_name else (region_name, '')
        
        return {
            'complex_id': f"naver_{apt.complex_no}" if apt.complex_no else f"naver_unknown_{id(apt)}",
            'complex_name': apt.complex_name or 'ì´ë¦„ì—†ìŒ',
            'address_road': apt.address or '',
            'city': city,
            'gu': gu,
            'latitude': apt.latitude,
            'longitude': apt.longitude,
            'total_units': apt.total_household_count,
            'construction_year': construction_year,
            'last_transaction_price': avg_price,
            'source_url': f"https://new.land.naver.com/complexes/{apt.complex_no}" if apt.complex_no else ""
        }
    
    async def crawl_and_save_region(self, city, district, trade_type='ë§¤ë§¤'):
        """ì§€ì—­ í¬ë¡¤ë§ í›„ DB ì €ì¥"""
        print(f"ğŸ—ï¸ {city} {district} {trade_type} í¬ë¡¤ë§ ì‹œì‘...")
        
        async with NaverRealEstateCrawler() as crawler:
            try:
                # í¬ë¡¤ë§ ì‹¤í–‰
                apartments = await crawler.get_apartments(city, district, trade_type)
                print(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ: {len(apartments)}ê°œ ì•„íŒŒíŠ¸")
                
                if not apartments:
                    print("âš ï¸ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    return
                
                # DB ì €ì¥
                region_name = f"{city}_{district}"
                saved_count = 0
                
                for apt in apartments:
                    try:
                        db_data = self.convert_apartment_to_db_format(apt, region_name)
                        
                        # upsertë¡œ ì¤‘ë³µ ë°©ì§€
                        result = self.setup.supabase.table('apartment_complexes')\
                            .upsert(db_data, on_conflict='complex_id')\
                            .execute()
                        
                        saved_count += 1
                        
                        if saved_count % 50 == 0:
                            print(f"ğŸ“¤ ì§„í–‰ë¥ : {saved_count}/{len(apartments)}")
                            
                    except Exception as e:
                        print(f"âš ï¸ ê°œë³„ ì €ì¥ ì˜¤ë¥˜: {e}")
                        continue
                
                print(f"ğŸ‰ DB ì €ì¥ ì™„ë£Œ: {saved_count}/{len(apartments)}ê°œ")
                return saved_count
                
            except Exception as e:
                print(f"âŒ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
                return 0
    
    async def crawl_seoul_districts(self, limit_districts=None):
        """ì„œìš¸ ì „ì²´ êµ¬ í¬ë¡¤ë§"""
        seoul_districts = [
            "ê°•ë‚¨êµ¬", "ê°•ë™êµ¬", "ê°•ë¶êµ¬", "ê°•ì„œêµ¬", "ê´€ì•…êµ¬",
            "ê´‘ì§„êµ¬", "êµ¬ë¡œêµ¬", "ê¸ˆì²œêµ¬", "ë…¸ì›êµ¬", "ë„ë´‰êµ¬",
            "ë™ëŒ€ë¬¸êµ¬", "ë™ì‘êµ¬", "ë§ˆí¬êµ¬", "ì„œëŒ€ë¬¸êµ¬", "ì„œì´ˆêµ¬",
            "ì„±ë™êµ¬", "ì„±ë¶êµ¬", "ì†¡íŒŒêµ¬", "ì–‘ì²œêµ¬", "ì˜ë“±í¬êµ¬",
            "ìš©ì‚°êµ¬", "ì€í‰êµ¬", "ì¢…ë¡œêµ¬", "ì¤‘êµ¬", "ì¤‘ë‘êµ¬"
        ]
        
        if limit_districts:
            seoul_districts = seoul_districts[:limit_districts]
        
        print(f"ğŸ™ï¸ ì„œìš¸ {len(seoul_districts)}ê°œ êµ¬ í¬ë¡¤ë§ ì‹œì‘")
        print("ğŸ”’ WARP í™œì„±í™” ìƒíƒœ")
        print("=" * 50)
        
        total_saved = 0
        
        for i, district in enumerate(seoul_districts, 1):
            print(f"\n[{i}/{len(seoul_districts)}] {district}")
            
            try:
                saved = await self.crawl_and_save_region("ì„œìš¸", district)
                total_saved += saved
                
                # ë„ˆë¬´ ë¹ ë¥¸ ìš”ì²­ ë°©ì§€ (3ì´ˆ ëŒ€ê¸°)
                print("â±ï¸ 3ì´ˆ ëŒ€ê¸°...")
                await asyncio.sleep(3)
                
            except Exception as e:
                print(f"âŒ {district} í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
                continue
        
        print(f"\nğŸ‰ ì „ì²´ í¬ë¡¤ë§ ì™„ë£Œ!")
        print(f"ğŸ“Š ì´ ì €ì¥ëœ ì•„íŒŒíŠ¸: {total_saved}ê°œ")
        
        return total_saved

async def main():
    print("ğŸš€ ì„œìš¸ ì•„íŒŒíŠ¸ í¬ë¡¤ë§ + DB ì €ì¥ ì‹œì‘!")
    print("=" * 50)
    
    crawler_db = SeoulCrawlerWithDB()
    
    # ë¨¼ì € 3ê°œ êµ¬ë§Œ í…ŒìŠ¤íŠ¸
    total_saved = await crawler_db.crawl_seoul_districts(limit_districts=3)
    
    print(f"\nğŸ“ˆ ìµœì¢… ê²°ê³¼: {total_saved}ê°œ ì•„íŒŒíŠ¸ DB ì €ì¥ ì™„ë£Œ")

if __name__ == "__main__":
    asyncio.run(main())